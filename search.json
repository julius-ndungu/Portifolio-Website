{
  "articles": [
    {
      "path": "Breast_Cancer_Prediction.html",
      "title": "Bulding a Machine Learning Model to Predict Breast Cancer Using R software",
      "author": [
        {
          "name": "Julius Ndung'u",
          "url": {}
        }
      ],
      "date": "2024-02-23",
      "contents": "\r\n\r\nContents\r\nIntroduction\r\nVariables\r\nRequired packages\r\nImporting the data and changing the data type of our target variable\r\nEDA\r\nChecking for Dublicates\r\nBalancing the Data by Oversampling\r\nSpliting the Data into Training and Testing\r\nBuilding a Randomforest Classification Model\r\nVariable Importance\r\nPredicting Using the Model\r\nTesting the Model Accuracy\r\nTable of Predicted Against the Actual values\r\nLimitation of the Model\r\nData souce\r\n\r\n\r\nIntroduction\r\nBreast cancer remains a significant global health concern, affecting millions of individuals worldwide and posing formidable challenges to healthcare systems. Timely and accurate diagnosis is paramount in guiding treatment decisions and improving patient outcomes. This project delves into the realm of predictive modeling specifically focused on breast cancer diagnosis. By harnessing the power of machine learning and leveraging a rich dataset comprising clinical and diagnostic features, this endeavor aims to develop a robust predictive model capable of discerning between malignant and benign tumors with high accuracy.\r\nVariables\r\nDiagnosis: This categorical variable indicates the diagnosis outcome, with “M” representing malignant tumors and “B” representing benign tumors. It serves as the target variable for prediction.\r\nRadius_mean, Texture_mean, Perimeter_mean: These variables represent the mean values of the radius, texture, and perimeter of the tumor cells, respectively, measured from diagnostic images.\r\nArea_mean, Smoothness_mean, Compactness_mean, Concavity_mean, Concave_points_mean: These variables capture additional morphological characteristics of tumor cells, such as the area, smoothness, compactness, concavity, and number of concave points in the cell nuclei, averaged across the diagnostic images.\r\nSymmetry_mean, Fractal_dimension_mean: These variables describe symmetry and fractal dimension features of tumor cells, providing insights into their structural complexity and irregularity.\r\nRadius_se, Texture_se, Perimeter_se, Area_se, Smoothness_se, Compactness_se, Concavity_se, Concave_points_se, Symmetry_se, Fractal_dimension_se: These variables represent the standard error (SE) of the corresponding morphological features, providing information about the variability or uncertainty in their measurements.\r\nRadius_worst, Texture_worst, Perimeter_worst, Area_worst, Smoothness_worst, Compactness_worst, Concavity_worst, Concave_points_worst, Symmetry_worst, Fractal_dimension_worst: These variables denote the “worst” or largest values of the respective morphological features observed in the tumor cells, providing insights into the most severe manifestations of tumor characteristics.\r\nRequired packages\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(randomForest)\r\nlibrary(lava)\r\nlibrary(janitor)\r\nlibrary(caret)\r\nlibrary(rsample)\r\nlibrary(DT)\r\n\r\n\r\nImporting the data and changing the data type of our target variable\r\n\r\n\r\ncancer <- read_csv(\"breast-cancer.csv\") %>% select(-id) %>% clean_names()\r\ncancer$diagnosis <- factor(cancer$diagnosis)\r\n\r\n\r\nEDA\r\n\r\n\r\ncancer %>% group_by(diagnosis) %>% \r\n  summarise(count = n()) %>% \r\n  ggplot(aes(diagnosis,count, label = count,fill = diagnosis))+geom_col()+geom_text(aes(label = count, vjust = 2))\r\n\r\n\r\n\r\n“B” indicates benign tumors.\r\n“M” indicates malignant tumors.\r\nThere are 357 instances of benign tumors (labelled as “B”).\r\nThere are 212 instances of malignant tumors (labelled as “M”).\r\nChecking for Dublicates\r\n\r\n\r\ncancer %>% duplicated() %>% unique()\r\n\r\n[1] FALSE\r\n\r\n\r\nThere are no dublicates\r\n\r\nBalancing the Data by Oversampling\r\n\r\n\r\ncancer <- upSample(cancer, cancer$diagnosis)\r\ncancer <- cancer %>% select(-Class)\r\ntable(cancer$diagnosis)\r\n\r\n\r\n  B   M \r\n357 357 \r\n\r\n\r\nThe data is now balanced\r\n\r\nSpliting the Data into Training and Testing\r\n\r\n\r\nset.seed(111)\r\n\r\nsplit <- initial_split(cancer, prop = 0.8, strata = diagnosis)\r\n\r\ntrain <- training(split)\r\ntest <- testing(split)\r\ntabyl(cancer$diagnosis)\r\n\r\n cancer$diagnosis   n percent\r\n                B 357     0.5\r\n                M 357     0.5\r\n\r\ntabyl(train$diagnosis)\r\n\r\n train$diagnosis   n percent\r\n               B 285     0.5\r\n               M 285     0.5\r\n\r\ntabyl(test$diagnosis)\r\n\r\n test$diagnosis  n percent\r\n              B 72     0.5\r\n              M 72     0.5\r\n\r\nBuilding a Randomforest Classification Model\r\n\r\n\r\nm1 <- randomForest(diagnosis ~ . , data = train)\r\nm1\r\n\r\n\r\nCall:\r\n randomForest(formula = diagnosis ~ ., data = train) \r\n               Type of random forest: classification\r\n                     Number of trees: 500\r\nNo. of variables tried at each split: 5\r\n\r\n        OOB estimate of  error rate: 2.46%\r\nConfusion matrix:\r\n    B   M class.error\r\nB 279   6  0.02105263\r\nM   8 277  0.02807018\r\n\r\nNumber of trees: The random forest consists of 500 individual decision trees. Random forests generate multiple decision trees during training and output the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees.\r\nNumber of variables tried at each split: At each split in the decision trees, the algorithm considers a random subset of 5 variables from the total set of predictor variables available in the dataset.\r\nOOB estimate of error rate: The out-of-bag (OOB) estimate is an estimate of the model’s error rate on unseen data. It’s computed using the data not included in the bootstrap sample used to grow the trees. In this case, the OOB error rate is 2.46%.\r\nConfusion matrix: The confusion matrix shows the model’s performance on the training data. It presents a tabular summary of the number of correct and incorrect predictions made by the model. In this confusion matrix:\r\nThe rows represent the actual classes (“B” for benign and “M” for malignant).\r\nThe columns represent the predicted classes.\r\nThe numbers in the matrix indicate the counts of instances.\r\nThe class.error column shows the error rate for each class. For example, the error rate for class “B” is 0.028 (or 2.8%), and the error rate for class “M” is 0.021 (or 2.1%).\r\nVariable Importance\r\n\r\n\r\nvarImp(m1) %>% arrange(desc(Overall)) %>% datatable()\r\n\r\n\r\n\r\n\r\nThese values represent the importance of each predictor variable in contributing to the accuracy of the random forest model. Higher values suggest that the variable is more important in predicting the target variable (in this case, the diagnosis of breast cancer).\r\n\r\nPredicting Using the Model\r\n\r\n\r\np <- predict(m1 , newdata = test, type = \"class\")\r\ntest$prediction <- p\r\n\r\n\r\nTesting the Model Accuracy\r\n\r\n\r\nconfusionMatrix(data = test$prediction, reference = test$diagnosis)\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction  B  M\r\n         B 70  2\r\n         M  2 70\r\n                                          \r\n               Accuracy : 0.9722          \r\n                 95% CI : (0.9304, 0.9924)\r\n    No Information Rate : 0.5             \r\n    P-Value [Acc > NIR] : <2e-16          \r\n                                          \r\n                  Kappa : 0.9444          \r\n                                          \r\n Mcnemar's Test P-Value : 1               \r\n                                          \r\n            Sensitivity : 0.9722          \r\n            Specificity : 0.9722          \r\n         Pos Pred Value : 0.9722          \r\n         Neg Pred Value : 0.9722          \r\n             Prevalence : 0.5000          \r\n         Detection Rate : 0.4861          \r\n   Detection Prevalence : 0.5000          \r\n      Balanced Accuracy : 0.9722          \r\n                                          \r\n       'Positive' Class : B               \r\n                                          \r\n\r\n\r\nAccuracy: 97.92% - This is the proportion of correct predictions out of the total number of predictions made.\r\n\r\nTable of Predicted Against the Actual values\r\n\r\n\r\ntest %>% select(diagnosis, prediction) %>% datatable()\r\n\r\n\r\n\r\nLimitation of the Model\r\nFeature Selection: The predictive power of the model heavily relies on the choice of input features. While the current model considers various features such as radius, texture, perimeter, area, and others, there might be other relevant features not included in the analysis. Incorporating additional features or exploring feature engineering techniques could potentially enhance the model’s performance.\r\nModel Interpretability: Random Forest models, like the one used here, are considered “black box” models, meaning they provide accurate predictions but offer limited interpretability. Understanding how individual features contribute to the model’s predictions can be challenging. Techniques such as feature importance analysis provide some insight but may not fully explain the underlying mechanisms driving the predictions.\r\nExternal Factors: The model’s predictions may be influenced by factors not captured in the dataset, such as patient demographics, genetic factors, or environmental variables. Failing to account for these external factors could introduce bias or limit the model’s predictive accuracy in real-world applications.\r\nData souce\r\nKaggle:\r\nlink: https://www.kaggle.com/datasets/yasserh/breast-cancer-dataset\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:45:55+03:00"
    },
    {
      "path": "Budget_deficit.html",
      "title": "Deficits and Economic Growth",
      "description": "Impact of Budget Deficits on Economic Growth: Evidence from Kenya\n",
      "author": [
        {
          "name": "Julius",
          "url": {}
        }
      ],
      "date": "2024-06-18",
      "contents": "\r\n\r\n\r\n\r\nBackground of the Study\r\nFiscal policy encompasses government decisions on taxation, spending, and borrowing aimed at shaping a country’s economy. A pivotal component of fiscal policy is the national budget, which outlines government revenue and expenditure plans for a specified period (Nizamuddin, 2021). A budget deficit occurs when government spending exceeds its revenue during a fiscal year (Dick, 2022). This deficit has profound implications for economic stability and growth. Globally, the COVID-19 pandemic precipitated an expansion in budget deficits as governments implemented extensive fiscal measures to buoy economies during periods of lockdown and reduced economic activity (Haroutunian et al., 2021). According to the International Monetary Fund (IMF), the average global budget deficit as a percentage of GDP was approximately 3.8% in 2020. Kenya, an emerging economy in Africa, has witnessed substantial economic growth over recent decades, driven by sectors such as agriculture (21.2% of GDP), manufacturing (17.7%), and services (61.1%) (Kenya National Bureau of Statistics, 2023). However, persistent budget deficits, averaging 8% of GDP over the past five years, have necessitated increased borrowing to cover shortfalls (Njarara, A., 2017). These deficits raise concerns among policymakers, economists, and international financial institutions regarding their impact on economic stability and long-term growth prospects.\r\nTrends in the Budget Deficit\r\nThe trend of Kenya’s budget deficit from 1990 to 2023 illustrates a fluctuating fiscal landscape characterized by periods of deficit expansion and contraction. Initially stable in the mid-2000s with moderate fluctuations, recent years have seen consistently high deficits, indicating sustained fiscal challenges. Significant peaks in deficits coincide with major economic events, such as the COVID-19 pandemic in 2020, suggesting a correlation between economic stressors and fiscal deficits.\r\n\r\n\r\n\r\n\r\nTrends in Economic Growth\r\nEconomic growth refers to the increase in the production of goods and services in an economy over a period of time. It is typically measured by the growth rate of real GDP. Economic growth is crucial for improving living standards, reducing poverty, and enhancing the overall economic health of a country. A budget deficit, which occurs when a government spends more than it earns, can influence economic growth in several ways. While deficit spending can stimulate growth by funding infrastructure, education, and other critical investments, excessive deficits might lead to higher debt levels, reducing the resources available for future growth.\r\n\r\n\r\n\r\n Initially, in the early 1990s, the economy appeared relatively stable, with modest fluctuations in growth rates. However, as the years progress, there are noticeable shifts in economic growth patterns. For instance, in the mid to late 1990s, there seems to be a period of sustained growth, as indicated by consistently positive growth rates. during this time, Kenya underwent significant economic reforms, including liberalization policies that aimed to open up the economy, attract foreign investment, and stimulate private sector growth. These reforms, initiated in the early 1990s, helped create a more conducive environment for business and investment, fostering economic expansion. Towards the later years of the observed period, economic growth becomes more variable, with both positive and negative growth rates recorded. These fluctuations in economic growth highlight the inherent volatility and complexity of Kenya’s economy, influenced by both domestic and international factors. Understanding these trends is one of the motivations for this study\r\n\r\n\r\n\r\n\r\nInterest Rates are the cost of borrowing money, typically expressed as a percentage of the principal. They influence consumer and business spending, saving, and investment decisions. Budget deficits can impact interest rates through the supply and demand for credit. When the government runs a deficit, it often borrows money by issuing bonds. This increased demand for credit can drive up interest rates, known as the “crowding out” effect, where higher rates discourage private investment. However, in certain economic conditions, particularly when there is underutilized capacity, government borrowing might not lead to higher interest rates.\r\nExchange Rate is the value of one currency for the purpose of conversion to another. It plays a crucial role in international trade and investment flows. A budget deficit can affect the exchange rate through its influence on interest rates and investor confidence. If a deficit leads to higher interest rates, it can attract foreign capital, leading to an appreciation of the domestic currency. Conversely, persistent large deficits might raise concerns about a country’s fiscal health, leading to a depreciation of its currency as investors seek safer assets.\r\nInflation is the rate at which the general level of prices for goods and services is rising, eroding purchasing power. The relationship between budget deficits and inflation can be complex. In the short term, deficit spending can boost aggregate demand, potentially leading to higher prices if the economy is at or near full capacity. However, if a government finances its deficit by borrowing rather than printing money, the inflationary impact may be muted. Long-term deficits, if not managed properly, can undermine confidence in the currency, leading to higher inflation expectations and actual inflation.\r\nSeveral theories argues that there is a positive effect of budget deficit on economic growth while others indicates that a budget deficit hurts economic growth. Keynesian theory developed by economist John Maynard Keynes during the 1930s argues that during economic downturns, government should engage in deficit spending to stimulate demand and boost economic activity. Classical theory viewed deficits as potentially harmful due to their impact on interest rates and private investments. Classical economists argued that government borrowing to finance budget deficits can crowd out private borrowers in the credit markets. Studies have been carried out to study the link between budget deficits and economic growth in the recent economic literature. A recent empirical work by Olaoye et al. (2023) found that fiscal deficit is the root cause of inflation in Sub-Saharan Africa (SSA) countries. According to Nizamuddin (2021) fiscal deficit is one of the causes of rising public debt and a source of economic vulnerability. Essentially, when a government consistently spends more than it earns, it needs to borrow to cover the shortfall, leading to an accumulation of debt. This reliance on borrowing can strain the economy, making it vulnerable to fluctuations in interest rates, investor sentiment, and overall economic conditions. Sharma and Mittal (2019) concluded that budget deficits hurt economic growth if they are not invested in capital formation. In contrast, similar study by Oyeleke (2021) found that budget deficits have a positive effect on economic growth. In a study conducted by Dick (2022), it was revealed that fiscal policy hinders the performance of macroeconomic indicators and the overall state of the economy. Ahmad and Aworinde (2019) did a study to see if the money governments borrow causes inflation in African countries. They found that yes, it does. This means African countries need to manage their spending better to avoid inflationary pressures. Kanchori (2020) argued that the Kenyan economy has a positive relationship with the budget deficit.\r\nLITERATURE REVIEW\r\nKeynesian Perspective\r\nKeynesian economics represents a foundational theory in macroeconomics, emphasizing the role of government intervention in managing economic fluctuations, particularly during periods of recession. According to Keynesian theory, budget deficits can serve as a potent tool for stimulating aggregate demand when private sector spending declines. This decline in spending often occurs due to factors such as reduced consumer confidence, diminished investment, and increased saving during economic downturns (Bernheim, 1989). By injecting additional demand into the economy through deficit-financed government expenditure, Keynesians argue that deficits can help offset the contraction in economic activity, thereby reducing unemployment and utilizing idle resources (Barro, 1989).\r\nCentral to the Keynesian view is the concept of the multiplier effect. When the government increases spending financed through deficits, it injects new money into the economy. This initial injection stimulates consumption and investment, triggering subsequent rounds of additional spending. As a result, the overall impact on output and income levels surpasses the initial increase in government spending (Baumol, 1955). However, the effectiveness of deficit spending according to Keynesian principles hinges on specific conditions. Firstly, the economy must have idle resources and underutilized capacity to absorb increased government spending without triggering inflation. If the economy operates at full capacity, deficit spending could lead to inflation rather than boosting output. Secondly, the impact of fiscal stimulus measures on aggregate demand varies based on factors such as the marginal propensity to consume, the extent of crowding out of private investment, and the responsiveness of investment to changes in interest rates (Friedman, 1980).\r\nClassical Economic Theories\r\nIn contrast to Keynesian economics, classical economic theories offer a different perspective on budget deficits. Classical economists argue that deficits may crowd out private investment by increasing interest rates, thereby reducing the availability of funds for private sector borrowing and investment. This phenomenon, known as the crowding-out effect, posits that government borrowing to finance deficits competes with private borrowers in the credit market, leading to higher interest rates and potentially dampening private sector investment.\r\nRicardian Equivalence Proposition\r\nThe Ricardian equivalence proposition presents yet another theoretical viewpoint on budget deficits. Coined by David Ricardo, this proposition suggests that consumers are forward-looking and anticipate future tax liabilities associated with government borrowing. According to this theory, individuals understand that deficits today imply higher taxes in the future to service government debt. As a result, they increase saving and reduce consumption to prepare for these expected future tax burdens. From a Ricardian perspective, deficit financing may have limited impact on aggregate demand and economic growth because households adjust their behavior to account for future fiscal obligations.\r\nFurthermore, the Ricardian equivalence proposition argues that a debt-financed deficit does not alter the current account balance or exchange rates significantly. This perspective implies that, regardless of whether the government finances its expenditures through debt or taxes, individuals’ consumption and saving decisions remain largely unaffected, thereby limiting the stimulative effect of deficits on economic growth (Ricardo, 1817).\r\nSources of Data\r\nVariable\r\nSource\r\nGDP\r\nCBK\r\nAnnual Exchange rate\r\nWorld Bank\r\nBudget deficit\r\nWorld Bank\r\nInflation\r\nWorld Bank\r\nReal interest rate\r\nWorld Bank\r\nDATA ANALYSIS AND INTERPRETATION\r\nDescriptive Statistics\r\nThe descriptive analysis reveals several key insights into the distribution and characteristics of the variables under study. GDP, a fundamental measure of economic output, shows a mean value of 3.70 and a median of 4.17, indicating a slightly right-skewed distribution with a skewness of -0.27. The data’s kurtosis of -0.79 suggests a relatively flat distribution compared to a normal distribution, although not excessively so. Budget deficit, reflecting the fiscal health of the economy, has a mean and median both at 3.70, with a wider spread indicated by its standard deviation of 3.11. The data exhibits a slight positive skewness (0.05) and moderate platykurtosis (-1.60), implying more data points in the tails of the distribution. Real interest rates, averaging 18.59%, demonstrate variability with a standard deviation of 6.80, indicating fluctuations in borrowing costs over time. The distribution is moderately positively skewed (skewness = 1.13), suggesting more observations on the lower end of the interest rate spectrum. Inflation, with a mean of 11.17% and a median of 8.43%, shows a right-skewed distribution (skewness = 2.02) and higher kurtosis (4.28), indicating a more peaked distribution around the mean. Exchange rates, averaging 77.99 units, exhibit a standard deviation of 14.65, suggesting moderate variability in currency values. The nearly symmetrical distribution (skewness = -0.06, kurtosis = 0.05) indicates a balanced spread of data points around the mean.\r\nvariable\r\nminimum\r\nmaximum\r\nmean\r\nMedian\r\nstd\r\nskewness\r\nkurtosis\r\nGDP\r\n-0.27\r\n8.06\r\n3.70\r\n4.17\r\n2.29\r\n-0.27\r\n-0.79\r\nBudget deficit\r\n0.84\r\n8.57\r\n3.70\r\n3.66\r\n3.11\r\n0.05\r\n-1.60\r\nreal interest rate\r\n12\r\n36.24\r\n18.59\r\n16.54\r\n6.80\r\n1.13\r\n0.10\r\ninflation\r\n1.55\r\n45.98\r\n11.17\r\n8.43\r\n9.13\r\n2.02\r\n4.28\r\nexchange rates\r\n22.91\r\n139.83\r\n77.99\r\n77.96\r\n14.65\r\n-0.06\r\n0.05\r\nCorrelation Analysis\r\ncorrelation measures the strength and direction of the linear relationship between two variables. The values range from -1 to 1. A correlation coefficient close to 1 indicates a strong positive linear relationship while a correlation coefficient close to -1 indicates a strong negative linear relationship. A correlation coefficient close to 0 indicates a weak or no linear relationship between the variables. Higher real interest rates are associated with lower GDP growth rates, correlation (-0.55) which is statistically significant.Higher interest rate can lead to reduced consumer and business spending, as borrowing cost increases. This reduction slows down economic growth. There is a moderate positive correlation (0.41) between GDP growth rate and exchange rate, and it is statistically significant. This suggests that a stronger exchange rate (depreciation) is associated with higher GDP growth rates. a higher exchange rate(domestic currency depreciation) can make country’s export more competitive in international market which leads to increase in export volumes, boosting economic growth. There is a negative correlation (-0.70) between interest rate and exchange rates indicating a strong inverse relationship between the two variables. This implies that periods of domestic currency depreciation(higher exchange rates) are strongly associated with periods of lower interest rate. Also a significant moderate inverse correlation(-0.53) exists between inflation and exchange rate. This indicates that higher exchange rate (weaker domestic currency) is asscociated with lower inflation and lower exchange rate(stronger domestic currency) is associated with higher inflation this is less common in most economics and kenya economics may be unique. Budget deficit has a positive moderate correlation(0.41) with exchange rates. this means that as the budget deficit increases the exchange rate also tends to increase.An increase in exchange rate implies depreciation of the domestic currency thus a positive correlation suggest that higher budget deficit are associated with weaker domestic currency.\r\n\r\n\r\n\r\nRegression Analysis\r\nThe regression analysis reveals insightful relationships between GDP growth and its predictors-specifically inflation, real interest rates, exchange rates, and the log of deficit. The intercept of 7.35 suggests that, in the absence of any predictor variables, the expected GDP growth rate would be 7.35%. Real interest rates show a statistically significant negative coefficient of -0.28 (p = 0.001), indicating that higher interest rates are associated with lower GDP growth rates. This relationship suggests that increased borrowing costs constrain consumer and business spending, thereby dampening economic growth. Conversely, while the coefficient for inflation is 0.03, it is not statistically significant (p = 0.767), implying that changes in inflation rates within the observed range do not reliably predict changes in GDP growth. Similarly, the exchange rate coefficient of 0.02 is not statistically significant (p = 0.246), indicating that fluctuations in exchange rates do not significantly influence GDP growth in this model. The log of deficit shows a marginally significant negative coefficient of -0.47 (p = 0.050), suggesting that larger deficits are associated with lower GDP growth rates. The model’s R-squared of 0.583 indicates that approximately 58.3% of the variation in GDP growth can be explained by the included predictors, with the adjusted R-squared of 0.510 adjusting for the model’s complexity.\r\n\r\n\r\n \r\n\r\n\r\ngdp growth\r\n\r\n\r\nPredictors\r\n\r\n\r\nEstimates\r\n\r\n\r\nCI\r\n\r\n\r\np\r\n\r\n\r\n(Intercept)\r\n\r\n\r\n7.35\r\n\r\n\r\n1.39 – 13.32\r\n\r\n\r\n0.018\r\n\r\n\r\ninflation\r\n\r\n\r\n0.03\r\n\r\n\r\n-0.18 – 0.24\r\n\r\n\r\n0.767\r\n\r\n\r\ninterest rate\r\n\r\n\r\n-0.28\r\n\r\n\r\n-0.43 – -0.13\r\n\r\n\r\n0.001\r\n\r\n\r\nexg rate\r\n\r\n\r\n0.02\r\n\r\n\r\n-0.02 – 0.06\r\n\r\n\r\n0.246\r\n\r\n\r\ndeficit [log]\r\n\r\n\r\n-0.47\r\n\r\n\r\n-0.93 – -0.00\r\n\r\n\r\n0.050\r\n\r\n\r\nObservations\r\n\r\n\r\n28\r\n\r\n\r\nR2 / R2 adjusted\r\n\r\n\r\n0.583 / 0.510\r\n\r\n\r\nAssumptions\r\n\r\n$NCV\r\n\r\n\r\n$HOMOGENEITY\r\n\r\n\r\n$VIF\r\n\r\n\r\n$QQ\r\n\r\n\r\n$NORM\r\n\r\n\r\nAll assumptions of the regression analysis have been satisfactorily met, ensuring the robustness of the model’s findings. The fulfillment of these assumptions, including but not limited to linearity, independence of errors, homoscedasticity (constant variance of errors), and absence of multicollinearity among predictors, supports the validity of the regression results. These conditions enhance confidence in the relationships identified between GDP growth and its predictors-real interest rates, inflation, exchange rates, and the log of deficit. Consequently, the interpretations drawn from the regression coefficients are more reliable, providing valuable insights into the factors influencing economic growth in the context of Kenya.\r\nMarginal Effect of each variable\r\nThe impact of each predictor variable on GDP was assessed using ggeffects, a package in R specifically designed for calculating marginal effects and predictions from statistical models. ggeffects was employed to estimate and visualize the predicted values of GDP based on changes in each predictor variable while holding other variables constant. This approach allowed for a detailed examination of how inflation, real interest rates, exchange rates, and the log of deficit individually influence GDP growth in the regression model.\r\n\r\n$inflation\r\n\r\n\r\n$interest_rate\r\n\r\n\r\n$exg_rate\r\n\r\n\r\n$deficit\r\n\r\n\r\nDiscussion of the Findings\r\nReal interest rates show a statistically significant negative relationship with GDP growth. The coefficient of -0.28 indicates that an increase in real interest rates is associated with a decrease in GDP growth rates by approximately 0.28 percentage points, holding other variables constant. This finding underscores the importance of monetary policy in influencing economic activity. Higher interest rates tend to raise the cost of borrowing for businesses and consumers, thereby reducing investment and spending levels. Consequently, economic growth may be stifled as a result of decreased consumption and investment expenditure.\r\nIn contrast, inflation does not show a statistically significant relationship with GDP growth in the regression model. The coefficient of 0.03 with a p-value of 0.767 suggests that changes in inflation rates within the observed range do not predictably impact GDP growth in Kenya. This outcome implies that inflation, at current levels, does not pose a significant hindrance or stimulant to economic expansion, which may reflect stable inflation expectations and effective monetary policy management.\r\nRegarding exchange rates, the regression results indicate a non-significant coefficient of 0.02 (p = 0.246). This suggests that fluctuations in exchange rates do not exert a significant influence on GDP growth in the context of Kenya. While a stronger exchange rate (domestic currency depreciation) theoretically enhances export competitiveness, thereby potentially boosting GDP through increased export volumes, the model does not detect a statistically significant effect. This finding underscores the complexity of exchange rate dynamics and their impact on overall economic performance.\r\nThe log of deficit, however, shows a marginally significant negative coefficient of -0.47 (p = 0.050). This indicates that larger deficits, as reflected in higher log values, are associated with lower GDP growth rates. The interpretation suggests that fiscal deficits, when not adequately managed or balanced with productive investments, may strain the economy by crowding out private investment and potentially leading to higher borrowing costs. This finding underscores the importance of fiscal discipline and effective allocation of public funds to support sustainable economic growth.\r\nOverall, the regression model explains approximately 58.3% of the variance in GDP growth, with an adjusted R-squared of 0.510. This indicates that while the included variables-real interest rates, inflation, exchange rates, and deficit-account for a significant portion of the variation in GDP growth, other factors not considered in this model may also influence economic performance in Kenya.\r\nConclusion\r\nThe study reveals that real interest rates exert a significant negative impact on GDP growth. Higher real interest rates are associated with lower economic growth rates, highlighting the importance of prudent monetary policy in fostering a conducive environment for investment and consumption.\r\nSecondly, inflation levels within the observed range do not significantly affect GDP growth in Kenya. This suggests that current inflation dynamics, likely influenced by effective monetary policy management, do not pose a significant obstacle to economic expansion.\r\nThirdly, exchange rate fluctuations do not show a statistically significant impact on GDP growth in the regression model. While a stronger exchange rate theoretically enhances export competitiveness, the model indicates that such fluctuations do not reliably predict changes in overall economic performance.\r\nMoreover, the analysis reveals a marginally significant negative relationship between the log of deficit and GDP growth. Larger deficits, when not effectively managed or offset by productive investments, are associated with lower economic growth rates. This underscores the importance of fiscal discipline and strategic allocation of public resources to support sustainable economic development.\r\nOverall, the regression model explains approximately 58.3% of the variance in GDP growth, with an adjusted R-squared of 0.510. This suggests that while the included variables-real interest rates, inflation, exchange rates, and deficit-account for a significant portion of GDP growth variability, there are likely other factors influencing economic performance in Kenya that warrant further exploration.\r\nReference\r\nAbsolom O. Nyang’au, and Joseph Abuga Orayo. 2016. “Econometric Analysis of Fiscal Performance in Kenya.” Zenodo, August. https://doi.org/10.5281/ZENODO.1466758.\r\nAl-Khedar, S. (1996). The effects of budget deficits on the exchange rate, interest rates and trade balance: Evidence from the G-7 countries. International Economic Journal, 10(2), 71-86. [DOI: 10.1080/10168739600000012]\r\nAmwaama, B. S.(2018). The relationship between budget deficit and economic growth in Namibia: An empirical investigation. Cogent Economics & Finance, 6(1),1-18. [DOI: 10.1080/23322039.2018.1434410]\r\nAriens, Sigert, Janne K. Adolf, and Eva Ceulemans. 2022. “Collinearity Issues in Autoregressive Models with Time-Varying Serially Dependent Covariates.” Multivariate Behavioral Research 58 (4): 687–705. https://doi.org/10.1080/00273171.2022.2095247.\r\nBrooks, Mollie E, McCoy, Michael W, and Bolker, Benjamin M. 2013. “A Method for Detecting Positive Growth Autocorrelation Without Marking Individuals.” Public Library of Science (PLoS). https://doi.org/10.5167/UZH-84858.\r\nDaba, Isubalew, Wondaferahu Mulugeta, and Atnafu Gebremeskel. 2023. “Effects of Fiscal Deficit on Economic Growth in Sub-Saharan Africa: A Dynamic Panel Data Analysis.” Journal of Science Technology and Arts Research (March): Vol. 12 No. 1 (2023). https://doi.org/10.20372/STAR.V12I1.05.\r\nDauti, B., & Elezi, S. (2022). Economic growth in the Central East European Union and the Western Balkan countries in the course of Stability and Growth Pact and COVID19. Zbornik Radova Ekonomskog Fakulteta u Rijeci Casopis Za Ekonomsku Teoriju i 25 Praksu/Proceedings of Rijeka Faculty of Economics Journal of Economics and Business, 40(1), 29–61. https://doi.org/ 10.18045/zbefri.2022.1.29\r\nDe Marco, Paulo, and Caroline Correa Nobrega. 2018. “Evaluating Collinearity Effects on Species Distribution Models: An Approach Based on Virtual Species Simulation.” Edited by Luciano Bosso. PLOS ONE 13 (9): e0202403. https://doi.org/10.1371/journal.pone.0202403.\r\nFatima, A., Abbas, F., & Abbasi, Z. (2012). An empirical analysis of budget deficit and economic growth: Evidence from Pakistan. International Journal of Business and Social Sciences, 3(17), 33-39\r\nFrank, Lawrence D., and Andy Hong. 2018. “The Health Impacts of Rail Transit Investment: Synthesis of Evidence and Methodologies to Date.” The University of British Columbia. https://doi.org/10.14288/1.0368618.\r\nGulcan,Y., & Bilman, S. (2005). The impact of budget deficit on real exchange rate: The Turkish case. Applied Economics, 37(10), 1165-1174. [DOI: 10.1080/00036840500109500]\r\nHakkio, C. S. (1996). Budget deficits and exchange rates: Further evidence from cointegration and causality tests. Journal of International Money and Finance, 15(5), 801-814. [DOI: 10.1016/S0261-5606(96)00031-8]\r\nHayo, Bernd, and Florian Neumeier. 2024. “Political Leaders’ Socioeconomic Background and Public Budget Deficits: Evidence from OECD Countries.” Philipps-University Marburg, January. https://doi.org/10.17192/ES2024.0171.\r\nKryeziu, N. H., & Hoxha, E. (2021). Fiscal Deficit and its effects on economic growth: Empirical evidence. International Journal of Finance & Banking Studies (2147-4486), 10(1), 62–70. https://doi.org/10.20525/ijfbs.v10i1.1064\r\nKryeziu, N. H., & Hoxha, E. (2021). Fiscal Deficit and its effects on economic growth: Empirical evidence. International Journal of Finance & Banking Studies (2147-4486), 10(1), 62–70. https://doi.org/10.20525/ijfbs.v10i1.1064\r\nLe Gallo, Julie, Fernando Lopez, and Coro Chasco. 2020. “Testing for Spatial Group-Wise Heteroskedasticity in Spatial Autocorrelation Regression Models: Lagrange Multiplier Scan Tests [Data Set and Code].” https://b2share.eudat.eu. https://doi.org/10.23728/B2SHARE.018E440E8B9548A79991EC7DEB231308.\r\nMatundura Erickson, Dr. Elvis Kiano, and Dr. Alfred Serem. 2022. “Macroeconomic Drivers of Economic Growth.” Zenodo, February. https://doi.org/10.5281/ZENODO.6274395.\r\nMediratta, Rishi P., Thomas B. Newman, and Marie E. Wang. 2023. “Research Methods: Diagnostic Test Characteristics.” Hospital Pediatrics 13 (6): e164–69.\r\nObed Kerimu, Issacs Kipruto Kemboi, and Dedan Oriewo Onganya. 2022. “Effect of Selected Macroeconomic Variables on Budget Deficit in Kenya.” Zenodo, November. https://doi.org/10.5281/ZENODO.7310454.\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:47:27+03:00"
    },
    {
      "path": "Contacts.html",
      "title": "Contacts",
      "author": [],
      "contents": "\r\nGet in Touch\r\nI’d love to hear from you! Whether you have a question about my projects, blogs, want to collaborate or just want to connect, feel free to reach out.\r\nEmail\r\nEmail Address\r\nLinkedln\r\nLinkedln Profile\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:47:31+03:00"
    },
    {
      "path": "customer_chunk.html",
      "title": "Customer churn prediction",
      "author": [
        {
          "name": "Julius Ndung'u",
          "url": {}
        }
      ],
      "date": "2024-04-30",
      "contents": "\r\nIntroduction\r\nIn the highly competitive telecom industry, retaining customers is crucial for sustained business success. Customer churn, the phenomenon where customers switch to another provider or stop using services altogether, poses a significant challenge for telecom companies. High churn rates can lead to revenue loss and decreased market share. Therefore, predicting customer churn and implementing effective retention strategies are imperative for telecom companies to maintain profitability and competitiveness.\r\nIn this project, I aim to develop a machine learning model to predict customer churn for a telecom company. By analyzing historical customer data and behavior, the aim is to identify patterns and factors that contribute to customer churn. Armed with this knowledge, the telecom company can take proactive measures to retain customers, such as offering targeted incentives, personalized experiences, and improved services.\r\nVariables\r\nGender: The gender of the customer.\r\nSeniorCitizen: Whether the customer is a senior citizen or not (1 = Yes, 0 = No).\r\nPartner: Whether the customer has a partner or not (Yes, No).\r\nDependents: Whether the customer has dependents or not (Yes, No).\r\nTenure: The length of time the customer has been with the company (in months).\r\nPhoneService: Whether the customer has a phone service or not (Yes, No).\r\nMultipleLines: Whether the customer has multiple lines or not (Yes, No, No phone service).\r\nInternetService: The type of internet service the customer has (DSL, Fiber optic, No).\r\nOnlineSecurity: Whether the customer has online security or not (Yes, No, No internet service).\r\nOnlineBackup: Whether the customer has online backup or not (Yes, No, No internet service).\r\nDeviceProtection: Whether the customer has device protection or not (Yes, No, No internet service).\r\nTechSupport: Whether the customer has tech support or not (Yes, No, No internet service).\r\nStreamingTV: Whether the customer has streaming TV or not (Yes, No, No internet service).\r\nStreamingMovies: Whether the customer has streaming movies or not (Yes, No, No internet service).\r\nContract: The type of contract the customer has (Month-to-month, One year, Two year).\r\nPaperlessBilling: Whether the customer uses paperless billing or not (Yes, No).\r\nPaymentMethod: The customer’s payment method (Electronic check, Mailed check, Bank transfer (automatic), Credit card (automatic)).\r\nMonthlyCharges: The amount charged to the customer monthly.\r\nTotalCharges: The total amount charged to the customer.\r\nChurn: Whether the customer churned or not (Yes, No).\r\nPackages\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(caret)\r\nlibrary(randomForest)\r\nlibrary(party)\r\nlibrary(rpart)\r\nlibrary(lava)\r\nlibrary(e1071)\r\nlibrary(rsample)\r\nlibrary(rpivotTable)\r\n\r\n\r\nData Importation and preprocessing\r\n\r\n\r\ncustomer_data <- read.csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\r\ncustomer_data$gender <- factor(customer_data$gender)\r\ncustomer_data$SeniorCitizen <- factor(customer_data$SeniorCitizen)\r\ncustomer_data$Partner <- factor(customer_data$Partner)\r\ncustomer_data$Dependents <- factor(customer_data$Dependents)\r\ncustomer_data$PhoneService  <- factor(customer_data$PhoneService )\r\ncustomer_data$MultipleLines <- factor(customer_data$MultipleLines)\r\ncustomer_data$InternetService <- factor(customer_data$InternetService)\r\ncustomer_data$OnlineSecurity <- factor(customer_data$OnlineSecurity)\r\ncustomer_data$OnlineBackup <- factor(customer_data$OnlineBackup)\r\ncustomer_data$DeviceProtection <- factor(customer_data$DeviceProtection)\r\ncustomer_data$TechSupport <- factor(customer_data$TechSupport)\r\ncustomer_data$StreamingTV <- factor(customer_data$StreamingTV)\r\ncustomer_data$StreamingMovies <- factor(customer_data$StreamingMovies)\r\ncustomer_data$Contract <- factor(customer_data$Contract)\r\ncustomer_data$PaperlessBilling  <- factor(customer_data$PaperlessBilling)\r\ncustomer_data$PaymentMethod  <- factor(customer_data$PaymentMethod)\r\ncustomer_data$Churn  <- factor(customer_data$Churn)\r\ncustomer_data <- customer_data %>% select(-1)\r\ncustomer_data <- customer_data %>% \r\n  filter(complete.cases(.))\r\n\r\n\r\nExploratory Data Analysis\r\nOverall Churn Rate\r\n\r\n\r\noverall_churn_rate <- mean(customer_data$Churn == \"Yes\")\r\noverall_churn_rate\r\n\r\n[1] 0.265785\r\n\r\n\r\nThe overall churn rate for the telecommunications company is approximately 26.54%.\r\nThis means that about 26.54% of the customers in the dataset have churned.\r\n\r\nGender\r\n\r\n\r\n# Gender vs. Churn\r\nggplot(customer_data, aes(x = gender, fill = Churn)) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Gender vs. Churn\", \r\n       x = \"Gender\", y = \"Proportion\",\r\n       fill = \"Churn\")\r\n\r\n\r\n\r\nSeniorCitizen\r\n\r\n\r\nggplot(customer_data, aes(x = SeniorCitizen, fill = Churn)) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Senior Citizen vs. Churn\", \r\n       x = \"Senior Citizen\", y = \"Proportion\",\r\n       fill = \"Churn\")\r\n\r\n\r\n\r\nPartner\r\n\r\n\r\nggplot(customer_data, aes(x = Partner, fill = Churn)) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Partner vs. Churn\", \r\n       x = \"Partner\", y = \"Proportion\",\r\n       fill = \"Churn\")\r\n\r\n\r\n\r\nDependents\r\n\r\n\r\n# Dependents vs. Churn\r\nggplot(customer_data, aes(x = Dependents, fill = Churn)) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Dependents vs. Churn\", \r\n       x = \"Dependents\", y = \"Proportion\",\r\n       fill = \"Churn\")\r\n\r\n\r\n\r\nPhoneService\r\n\r\n\r\n# PhoneService vs. Churn\r\nggplot(customer_data, aes(x = PhoneService, fill = Churn)) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Phone Service vs. Churn\", \r\n       x = \"Phone Service\", y = \"Proportion\",\r\n       fill = \"Churn\")\r\n\r\n\r\n\r\nMultipleLines\r\n\r\n\r\n# MultipleLines vs. Churn\r\nggplot(customer_data, aes(x = MultipleLines, fill = Churn)) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Multiple Lines vs. Churn\", \r\n       x = \"Multiple Lines\", y = \"Proportion\",\r\n       fill = \"Churn\")\r\n\r\n\r\n\r\nInternetService\r\n\r\n\r\n# InternetService vs. Churn\r\nggplot(customer_data, aes(x = InternetService, fill = Churn)) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Internet Service vs. Churn\", \r\n       x = \"Internet Service\", y = \"Proportion\",\r\n       fill = \"Churn\")\r\n\r\n\r\n\r\nOnlineSecurity\r\n\r\n\r\n# OnlineSecurity vs. Churn\r\nggplot(customer_data, aes(x = OnlineSecurity, fill = Churn)) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Online Security vs. Churn\", \r\n       x = \"Online Security\", y = \"Proportion\",\r\n       fill = \"Churn\")\r\n\r\n\r\n\r\nOnlineBackup\r\n\r\n\r\n# OnlineBackup vs. Churn\r\nggplot(customer_data, aes(x = OnlineBackup, fill = Churn)) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Online Backup vs. Churn\", \r\n       x = \"Online Backup\", y = \"Proportion\",\r\n       fill = \"Churn\")\r\n\r\n\r\n\r\nDeviceProtection\r\n\r\n\r\n# DeviceProtection vs. Churn\r\nggplot(customer_data, aes(x = DeviceProtection, fill = Churn)) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Device Protection vs. Churn\", \r\n       x = \"Device Protection\", y = \"Proportion\",\r\n       fill = \"Churn\")\r\n\r\n\r\n\r\nTechSupport\r\n\r\n\r\n# TechSupport vs. Churn\r\nggplot(customer_data, aes(x = TechSupport, fill = Churn)) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Tech Support vs. Churn\", \r\n       x = \"Tech Support\", y = \"Proportion\",\r\n       fill = \"Churn\")\r\n\r\n\r\n\r\nStreamingTV\r\n\r\n\r\n# StreamingTV vs. Churn\r\nggplot(customer_data, aes(x = StreamingTV, fill = Churn)) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Streaming TV vs. Churn\", \r\n       x = \"Streaming TV\", y = \"Proportion\",\r\n       fill = \"Churn\")\r\n\r\n\r\n\r\nStreamingMovies\r\n\r\n\r\n# StreamingMovies vs. Churn\r\nggplot(customer_data, aes(x = StreamingMovies, fill = Churn)) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Streaming Movies vs. Churn\", \r\n       x = \"Streaming Movies\", y = \"Proportion\",\r\n       fill = \"Churn\")\r\n\r\n\r\n\r\nContract\r\n\r\n\r\n# Contract vs. Churn\r\nggplot(customer_data, aes(x = Contract, fill = Churn)) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Contract vs. Churn\", \r\n       x = \"Contract\", y = \"Proportion\",\r\n       fill = \"Churn\")\r\n\r\n\r\n\r\nPaperlessBilling\r\n\r\n\r\n# PaperlessBilling vs. Churn\r\nggplot(customer_data, aes(x = PaperlessBilling, fill = Churn)) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Paperless Billing vs. Churn\", \r\n       x = \"Paperless Billing\", y = \"Proportion\",\r\n       fill = \"Churn\")\r\n\r\n\r\n\r\nPaymentMethod\r\n\r\n\r\n# PaymentMethod vs. Churn\r\nggplot(customer_data, aes(x = PaymentMethod, fill = Churn)) +\r\n  geom_bar(position = \"fill\") +\r\n  labs(title = \"Payment Method vs. Churn\", \r\n       x = \"Payment Method\", y = \"Proportion\",\r\n       fill = \"Churn\")\r\n\r\n\r\n\r\nData Partationing\r\n\r\n\r\nset.seed(123)\r\ncustomer_data <- upSample(customer_data,customer_data$Churn)\r\ncustomer_data <- customer_data %>% select(-Class)\r\nset.seed(123)\r\nsplit <- initial_split(customer_data, prop = 0.80, strata = Churn)\r\ntrain <- training(split)\r\ntest<- testing(split)\r\n\r\n\r\nDifferent Models\r\n\r\n\r\nset.seed(123)\r\n#randomforest\r\nmodel1 <- randomForest(Churn ~ ., data = train, importance = TRUE)\r\n#tree1\r\nmodel2 <- ctree(Churn ~ ., data = train,controls = ctree_control(mincriterion = 0.99))\r\n#tree2\r\nmodel3 <- rpart(Churn ~ ., data = train)\r\n#svm\r\nmodel4 <- svm(Churn ~ ., data = train)\r\n#naivebayes\r\nmodel5 <- naiveBayes(Churn ~ ., data = train)\r\n\r\n\r\nPrediction\r\n\r\n\r\nprediction1 <- predict(model1, test,type = \"response\")\r\nprediction2<-predict(model2, test,type = \"response\")\r\nprediction3<- predict(model3, test,type = \"class\")\r\nprediction4 <- predict(model4, test,type = \"response\")\r\nprediction5 <- predict(model5, test,type = \"class\")\r\n\r\n\r\nAccuracy\r\nModel 1\r\n\r\n\r\nconfusionMatrix(prediction1, test$Churn, positive = \"Yes\")\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction  No Yes\r\n       No  835  46\r\n       Yes 198 987\r\n                                          \r\n               Accuracy : 0.8819          \r\n                 95% CI : (0.8672, 0.8955)\r\n    No Information Rate : 0.5             \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.7638          \r\n                                          \r\n Mcnemar's Test P-Value : < 2.2e-16       \r\n                                          \r\n            Sensitivity : 0.9555          \r\n            Specificity : 0.8083          \r\n         Pos Pred Value : 0.8329          \r\n         Neg Pred Value : 0.9478          \r\n             Prevalence : 0.5000          \r\n         Detection Rate : 0.4777          \r\n   Detection Prevalence : 0.5736          \r\n      Balanced Accuracy : 0.8819          \r\n                                          \r\n       'Positive' Class : Yes             \r\n                                          \r\n\r\n\r\nModel Accuracy is 88.19%\r\n\r\nModel 2\r\n\r\n\r\nconfusionMatrix(prediction2, test$Churn, positive = \"Yes\")\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction  No Yes\r\n       No  707 169\r\n       Yes 326 864\r\n                                          \r\n               Accuracy : 0.7604          \r\n                 95% CI : (0.7414, 0.7787)\r\n    No Information Rate : 0.5             \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.5208          \r\n                                          \r\n Mcnemar's Test P-Value : 2.355e-12       \r\n                                          \r\n            Sensitivity : 0.8364          \r\n            Specificity : 0.6844          \r\n         Pos Pred Value : 0.7261          \r\n         Neg Pred Value : 0.8071          \r\n             Prevalence : 0.5000          \r\n         Detection Rate : 0.4182          \r\n   Detection Prevalence : 0.5760          \r\n      Balanced Accuracy : 0.7604          \r\n                                          \r\n       'Positive' Class : Yes             \r\n                                          \r\n\r\n\r\nModel Accuracy is 76.04%\r\n\r\nModel 3\r\n\r\n\r\nconfusionMatrix(prediction3, test$Churn, positive = \"Yes\")\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction  No Yes\r\n       No  757 231\r\n       Yes 276 802\r\n                                         \r\n               Accuracy : 0.7546         \r\n                 95% CI : (0.7354, 0.773)\r\n    No Information Rate : 0.5            \r\n    P-Value [Acc > NIR] : < 2e-16        \r\n                                         \r\n                  Kappa : 0.5092         \r\n                                         \r\n Mcnemar's Test P-Value : 0.05069        \r\n                                         \r\n            Sensitivity : 0.7764         \r\n            Specificity : 0.7328         \r\n         Pos Pred Value : 0.7440         \r\n         Neg Pred Value : 0.7662         \r\n             Prevalence : 0.5000         \r\n         Detection Rate : 0.3882         \r\n   Detection Prevalence : 0.5218         \r\n      Balanced Accuracy : 0.7546         \r\n                                         \r\n       'Positive' Class : Yes            \r\n                                         \r\n\r\n\r\nModel Accuracy is 75.46%\r\n\r\nModel 4\r\n\r\n\r\nconfusionMatrix(prediction4, test$Churn, positive = \"Yes\")\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction  No Yes\r\n       No  743 193\r\n       Yes 290 840\r\n                                          \r\n               Accuracy : 0.7662          \r\n                 95% CI : (0.7474, 0.7843)\r\n    No Information Rate : 0.5             \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.5324          \r\n                                          \r\n Mcnemar's Test P-Value : 1.253e-05       \r\n                                          \r\n            Sensitivity : 0.8132          \r\n            Specificity : 0.7193          \r\n         Pos Pred Value : 0.7434          \r\n         Neg Pred Value : 0.7938          \r\n             Prevalence : 0.5000          \r\n         Detection Rate : 0.4066          \r\n   Detection Prevalence : 0.5470          \r\n      Balanced Accuracy : 0.7662          \r\n                                          \r\n       'Positive' Class : Yes             \r\n                                          \r\n\r\n\r\nModel Accuracy is 76.62%\r\n\r\nModel 5\r\n\r\n\r\nconfusionMatrix(prediction5, test$Churn, positive = \"Yes\")\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction  No Yes\r\n       No  677 163\r\n       Yes 356 870\r\n                                          \r\n               Accuracy : 0.7488          \r\n                 95% CI : (0.7295, 0.7674)\r\n    No Information Rate : 0.5             \r\n    P-Value [Acc > NIR] : < 2.2e-16       \r\n                                          \r\n                  Kappa : 0.4976          \r\n                                          \r\n Mcnemar's Test P-Value : < 2.2e-16       \r\n                                          \r\n            Sensitivity : 0.8422          \r\n            Specificity : 0.6554          \r\n         Pos Pred Value : 0.7096          \r\n         Neg Pred Value : 0.8060          \r\n             Prevalence : 0.5000          \r\n         Detection Rate : 0.4211          \r\n   Detection Prevalence : 0.5934          \r\n      Balanced Accuracy : 0.7488          \r\n                                          \r\n       'Positive' Class : Yes             \r\n                                          \r\n\r\n\r\nModel Accuracy is 74.88%\r\n\r\nBest Model\r\nBased on the results of the confusion matrices obtained from different classification models, the random forest model (model1) appears to be the best performing model for predicting customer churn. Here’s why:\r\nAccuracy\r\nThe random forest model achieved the highest accuracy of 88.19% compared to other models. This indicates that the random forest model correctly predicted churn and non-churn cases in the test dataset 88.19% of the time.\r\nSensitivity (True Positive Rate)\r\nThe random forest model achieved the highest sensitivity of 95.55%, indicating that it correctly identified 95.55% of churn cases in the test dataset.\r\nSpecificity (True Negative Rate):\r\nThe random forest model also had a high specificity of 80.83%, meaning that it correctly identified 80.83% of non-churn cases in the test dataset.\r\nPositive Predictive Value (Precision):\r\nThe positive predictive value (PPV) of the random forest model was 83.29%, which indicates that of all the cases predicted as churn, 83.29% were actually churn.\r\nBalanced Accuracy:\r\nThe balanced accuracy of the random forest model was 88.19%, which takes into account both sensitivity and specificity. It indicates how well the model performs overall, considering both churn and non-churn cases.\r\nConclusion\r\nThe random forest model is the most suitable for predicting customer churn in the dataset.\r\nImportant Variables\r\n\r\n\r\nimportance(model1)\r\n\r\n                        No       Yes MeanDecreaseAccuracy\r\ngender            1.366282  84.37695             76.66513\r\nSeniorCitizen    10.891454  62.65898             59.64750\r\nPartner           2.652793  63.19316             61.33365\r\nDependents       -1.850204  59.53034             57.23929\r\ntenure           17.917240  77.98235             81.69964\r\nPhoneService     -3.600664  26.97762             27.52334\r\nMultipleLines    -2.799232  70.85387             68.16808\r\nInternetService  11.621901  43.80639             43.89906\r\nOnlineSecurity    9.754780  56.42618             46.91436\r\nOnlineBackup      7.103334  48.13169             40.98766\r\nDeviceProtection  8.418862  34.27538             31.96600\r\nTechSupport       9.129162  48.75672             41.41004\r\nStreamingTV       4.503089  37.16808             35.13310\r\nStreamingMovies   6.425203  40.34891             36.83717\r\nContract         10.699867  61.73690             66.27545\r\nPaperlessBilling  2.878819  73.77089             72.70996\r\nPaymentMethod    12.716184  84.23462             79.84615\r\nMonthlyCharges    4.789991 100.20921            102.10965\r\nTotalCharges     13.745703  94.57528            103.13354\r\n                 MeanDecreaseGini\r\ngender                   83.09962\r\nSeniorCitizen            58.24528\r\nPartner                  71.93571\r\nDependents               61.47103\r\ntenure                  590.06467\r\nPhoneService             14.76170\r\nMultipleLines            75.83001\r\nInternetService         165.27295\r\nOnlineSecurity          194.94692\r\nOnlineBackup            101.69893\r\nDeviceProtection         89.40107\r\nTechSupport             151.86483\r\nStreamingTV              72.72075\r\nStreamingMovies          76.35606\r\nContract                456.46056\r\nPaperlessBilling         78.25753\r\nPaymentMethod           217.05183\r\nMonthlyCharges          535.44104\r\nTotalCharges            596.62006\r\n\r\nTenure (tenure), Total Charges (TotalCharges), and Monthly Charges (MonthlyCharges) are the top three most important variables for predicting customer churn.\r\ntenure: Customers’ tenure with the company has the highest impact on predicting churn. Customers with longer tenure are less likely to churn.\r\nTotalCharges and MonthlyCharges: Higher total and monthly charges are associated with higher churn rates.\r\nAmong the service-related variables:\r\nInternet Service (InternetService) and Payment Method (PaymentMethod) are among the most important predictors of churn.\r\nWithin internet services, Fiber optic customers are more likely to churn compared to DSL and No internet service customers.\r\nContract Type (Contract) and Paperless Billing (PaperlessBilling) also play significant roles in predicting churn.\r\nCustomers with month-to-month contracts are more likely to churn compared to those with one or two-year contracts.\r\nCustomers who opt for paperless billing are more likely to churn.\r\nSenior Citizen (SeniorCitizen) status and Dependents (Dependents) also show notable impacts on churn.\r\nSenior citizens are more likely to churn compared to non-senior citizens.\r\nCustomers without dependents are more likely to churn.\r\nGender, Partner, Phone Service, Multiple Lines, Online Security, Online Backup, Device Protection, Tech Support, Streaming TV, and Streaming Movies have relatively lower importance compared to other variables but still contribute to predicting churn.\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:50:02+03:00"
    },
    {
      "path": "Customer_Segmentation.html",
      "title": "Customer Segmentation using K-means Clustering: A Data-driven Approach in R",
      "author": [
        {
          "name": "Julius Ndung'u",
          "url": {}
        }
      ],
      "date": "2024-04-22",
      "contents": "\r\nIntroduction\r\nIn today’s competitive business landscape, understanding and effectively catering to the needs of your customers is paramount for success. Customer segmentation, the practice of dividing customers into groups based on shared characteristics, allows businesses to personalize marketing efforts, optimize product offerings, and enhance overall customer experience.\r\nIn this project, I will delve into the world of customer segmentation using k-means clustering, a powerful machine learning algorithm. K-means clustering is an unsupervised learning technique that automatically groups similar data points together, making it an ideal choice for segmenting customers based on their demographic and behavioral traits.\r\nThrough this project, I aim to demonstrate my proficiency in data analysis and cleaning using R, a widely used programming language in the field of data science. By leveraging real-world customer data, I will showcase how k-means clustering can be employed to segment customers effectively.\r\nLoad Required Packages\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(fastDummies)\r\nlibrary(factoextra)\r\nlibrary(DT)\r\n\r\n\r\nLoad and Explore Data\r\n\r\n\r\ncustomer <- read.csv(\"train.csv\")\r\nhead(customer)\r\n\r\n      ID Gender Ever_Married Age Graduated    Profession\r\n1 462809   Male           No  22        No    Healthcare\r\n2 462643 Female          Yes  38       Yes      Engineer\r\n3 466315 Female          Yes  67       Yes      Engineer\r\n4 461735   Male          Yes  67       Yes        Lawyer\r\n5 462669 Female          Yes  40       Yes Entertainment\r\n6 461319   Male          Yes  56        No        Artist\r\n  Work_Experience Spending_Score Family_Size Var_1 Segmentation\r\n1               1            Low           4 Cat_4            D\r\n2              NA        Average           3 Cat_4            A\r\n3               1            Low           1 Cat_6            B\r\n4               0           High           2 Cat_6            B\r\n5              NA           High           6 Cat_6            A\r\n6               0        Average           2 Cat_6            C\r\n\r\nData Preprocessing\r\n\r\n\r\ncustomer_data <- customer[,2:9]\r\n\r\ncustomer_data[customer_data == \"\"] <- NA\r\ncustomer_data <- customer_data %>% \r\n  filter(complete.cases(.))\r\ndata_numeric <- customer_data %>% select_if(is.numeric)\r\ndata_character <- customer_data %>% select_if(is.character)\r\ndata_character <- dummy_cols(data_character,\r\n                             remove_most_frequent_dummy = TRUE)\r\ndata_character <- data_character %>% select(-c(1,2,3,4,5))\r\ncustomer <- cbind(data_numeric, data_character)\r\n\r\n\r\nScale Data\r\n\r\n\r\ndata_scale <- data.frame(scale(customer))\r\nhead(data_scale)\r\n\r\n         Age Work_Experience Family_Size Gender_Female\r\n1 -1.3034647      -0.4786562   0.7603344    -0.9025373\r\n2  1.4216419      -0.4786562  -1.2090499     1.1078226\r\n3  1.4216419      -0.7723730  -0.5525885    -0.9025373\r\n4  0.7555047      -0.7723730  -0.5525885    -0.9025373\r\n5 -0.6978855      -0.4786562   0.1038729    -0.9025373\r\n6 -0.6373275      -0.4786562   0.1038729     1.1078226\r\n  Ever_Married_No Graduated_No Profession_Doctor Profession_Engineer\r\n1       1.2037141    1.3240158        -0.3114177          -0.3091117\r\n2      -0.8306384   -0.7551656        -0.3114177           3.2345952\r\n3      -0.8306384   -0.7551656        -0.3114177          -0.3091117\r\n4      -0.8306384    1.3240158        -0.3114177          -0.3091117\r\n5       1.2037141   -0.7551656        -0.3114177          -0.3091117\r\n6       1.2037141   -0.7551656        -0.3114177          -0.3091117\r\n  Profession_Entertainment Profession_Executive Profession_Healthcare\r\n1               -0.3715439           -0.2862963             2.2733660\r\n2               -0.3715439           -0.2862963            -0.4398109\r\n3               -0.3715439           -0.2862963            -0.4398109\r\n4               -0.3715439           -0.2862963            -0.4398109\r\n5               -0.3715439           -0.2862963             2.2733660\r\n6               -0.3715439           -0.2862963             2.2733660\r\n  Profession_Homemaker Profession_Lawyer Profession_Marketing\r\n1           -0.1649639        -0.2844665           -0.1895355\r\n2           -0.1649639        -0.2844665           -0.1895355\r\n3           -0.1649639         3.5148294           -0.1895355\r\n4           -0.1649639        -0.2844665           -0.1895355\r\n5           -0.1649639        -0.2844665           -0.1895355\r\n6           -0.1649639        -0.2844665           -0.1895355\r\n  Spending_Score_Average Spending_Score_High\r\n1             -0.5767344          -0.4211066\r\n2             -0.5767344          -0.4211066\r\n3             -0.5767344           2.3743421\r\n4              1.7336423          -0.4211066\r\n5             -0.5767344          -0.4211066\r\n6             -0.5767344          -0.4211066\r\n\r\nDetermine Optimal Number of Clusters\r\n\r\n\r\nset.seed(111)\r\nfviz_nbclust(data_scale, kmeans, method = \"wss\")+\r\n  labs(subtitle = \"Elbow Method\")\r\n\r\n\r\n\r\n\r\nAfter visualizing the within-cluster sum of squares (WSS) for different numbers of clusters using the elbow method, it is observed that the plot displayed a clear ‘elbow point’ at k=6. The elbow point signifies the point at which adding more clusters ceases to significantly reduce the WSS. Prior to this point, increasing the number of clusters leads to a rapid decrease in WSS, indicating improved clustering performance. However, beyond the elbow point, the rate of decrease in WSS diminishes, suggesting that additional clusters may not capture substantially more variance in the data. Therefore, based on this analysis, i selected 6 clusters as the optimal number to effectively capture the underlying structure of the data while avoiding overfitting.\r\n\r\nKmean Clustering\r\n\r\n\r\nset.seed(1)\r\ncluster <- kmeans(data_scale, centers = 6)\r\n\r\n\r\nExplanation of Each Cluster.\r\n\r\n\r\n# Summarize the characteristics of each cluster\r\ncustomer <- customer %>% mutate(cluster = cluster$cluster)\r\ncluster_summary <- customer  %>%\r\n  group_by(cluster) %>%\r\n  summarise_all(list(mean = mean))\r\n(round(cluster_summary,2)) %>% data.frame()\r\n\r\n  cluster Age_mean Work_Experience_mean Family_Size_mean\r\n1       1    39.89                 3.42             2.45\r\n2       2    41.63                 2.62             2.97\r\n3       3    37.23                 2.59             2.86\r\n4       4    26.63                 2.58             3.78\r\n5       5    37.94                 6.44             2.29\r\n6       6    55.92                 1.82             2.72\r\n  Gender_Female_mean Ever_Married_No_mean Graduated_No_mean\r\n1               0.43                 0.62              0.30\r\n2               0.80                 0.38              0.54\r\n3               0.43                 0.54              0.42\r\n4               0.42                 0.89              0.65\r\n5               0.83                 0.45              0.43\r\n6               0.37                 0.02              0.22\r\n  Profession_Doctor_mean Profession_Engineer_mean\r\n1                      0                        0\r\n2                      0                        1\r\n3                      1                        0\r\n4                      0                        0\r\n5                      0                        0\r\n6                      0                        0\r\n  Profession_Entertainment_mean Profession_Executive_mean\r\n1                          0.45                      0.01\r\n2                          0.00                      0.00\r\n3                          0.00                      0.00\r\n4                          0.00                      0.00\r\n5                          0.00                      0.00\r\n6                          0.01                      0.20\r\n  Profession_Healthcare_mean Profession_Homemaker_mean\r\n1                       0.00                         0\r\n2                       0.00                         0\r\n3                       0.00                         0\r\n4                       0.99                         0\r\n5                       0.00                         1\r\n6                       0.00                         0\r\n  Profession_Lawyer_mean Profession_Marketing_mean\r\n1                    0.0                      0.12\r\n2                    0.0                      0.00\r\n3                    0.0                      0.00\r\n4                    0.0                      0.00\r\n5                    0.0                      0.00\r\n6                    0.2                      0.00\r\n  Spending_Score_Average_mean Spending_Score_High_mean\r\n1                        0.17                     0.02\r\n2                        0.31                     0.09\r\n3                        0.27                     0.04\r\n4                        0.03                     0.03\r\n5                        0.26                     0.10\r\n6                        0.38                     0.35\r\n\r\nCluster 1: This cluster represents a demographic of late-thirties career-oriented singles. They possess moderate work experience and tend to have smaller family sizes. Despite their relatively short tenure in the workforce, they exhibit a strong affinity for specialized professions like medicine and engineering, indicating a commitment to early career development. Predominantly female and unmarried, they likely prioritize professional advancement over family life. Despite their education and career focus, they maintain conservative spending habits, suggesting a cautious approach to finances. Marketing strategies for this group could emphasize career growth opportunities, professional networking events, and budget-friendly lifestyle products tailored to their early career aspirations.\r\nCluster 2: This cluster comprises individuals in their early forties with slightly higher work experience and larger family sizes compared to Cluster 1. The majority are female and married, with a notable proportion holding graduate degrees. Many work as engineers, suggesting a focus on technical professions. They exhibit a higher propensity for spending, especially on average and high-end products. Marketing efforts could target their family-oriented lifestyle, offering products and services that cater to their professional needs while accommodating their familial responsibilities.\r\nCluster 3: Individuals in this cluster are slightly younger, in their late thirties, with work experience and family sizes similar to Cluster 1. They show a balanced distribution in terms of marriage and education status. Notably, a significant portion work as doctors, indicating a strong presence in the healthcare profession. Their spending behavior leans towards the average range. Marketing strategies could focus on healthcare-related products and services, as well as career development opportunities for professionals in the medical field.\r\nCluster 4: This cluster represents a younger demographic, with individuals in their mid-twenties. They have lower work experience but larger family sizes compared to other clusters. The majority are unmarried and exhibit a lower rate of graduation. Almost all individuals in this cluster work in healthcare, suggesting a concentration in entry-level healthcare roles. Their spending tends to be low, reflecting their early career stage and possibly limited disposable income. Marketing strategies could target their specific needs as young professionals entering the healthcare field, offering educational resources and affordable products tailored to their lifestyle.\r\nCluster 5: Individuals in this cluster are similar in age to Cluster 3 but exhibit higher work experience and smaller family sizes. The majority are female, with a significant proportion being homemakers. They demonstrate a moderate spending behavior, with a notable percentage having a high spending score. Marketing efforts could focus on products and services that enhance their homemaking experience, as well as offerings that cater to their higher spending capacity, such as luxury household items or leisure activities.\r\nCluster 6: This cluster represents the oldest demographic, with individuals in their mid-fifties. They have the lowest work experience among the clusters but maintain moderate family sizes. Most are married and highly educated. While they have low representation in healthcare and entertainment professions, a significant portion work as executives, indicating a focus on leadership roles. They exhibit the highest average spending score, suggesting a comfortable financial position. Marketing strategies could target their affluent lifestyle, offering high-end products, exclusive experiences, and retirement planning services tailored to their needs and preferences.\r\nConclusion\r\nCustomer segmentation is a crucial step in understanding your customer base and tailoring marketing strategies to specific groups. In this project, I successfully segmented customers using k-means clustering based on their demographic and behavioral characteristics. By analyzing these segments, businesses can develop targeted marketing campaigns, optimize product offerings, and improve customer satisfaction and retention. K-means clustering in R provides a powerful tool for customer segmentation and can be further extended with additional analysis and interpretation.\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:52:22+03:00"
    },
    {
      "path": "DASHBOARDS.html",
      "title": "DASHBOARDS",
      "author": [
        {
          "name": "Ndung'u Julius",
          "url": {}
        }
      ],
      "date": "2024-02-05",
      "contents": "\r\n\r\nContents\r\nIntroduction to Dashboards\r\nWhat are Dashboards?\r\nImportance of Dashboards\r\nTypes of Dashboards:\r\nBasic procedure of creating a dashboard:\r\nExamples\r\n\r\n\r\nIntroduction to Dashboards\r\nDashboards play a pivotal role in transforming raw data into meaningful insights, providing a visually intuitive interface for users to interact with complex datasets. Whether in business, healthcare, finance, or any other domain, dashboards serve as powerful tools for decision-makers to monitor key metrics, track performance, and uncover trends.\r\nUsually dashboards intends to convey different, but related information in an easy-to-digest form\r\nWhat are Dashboards?\r\nA dashboard is a visual representation of data, consolidating diverse information into a unified display.\r\nIt acts as a centralized hub, presenting critical metrics and KPIs (Key Performance Indicators) in real-time or through periodic updates.\r\nDashboards can be static or interactive, allowing users to explore data, filter information, and gain a deeper understanding of the underlying trends.\r\nImportance of Dashboards\r\nData Visualization\r\nDashboards leverage charts, graphs, and other visual elements to present complex datasets in a digestible format. Visualizations enhance data comprehension, making it easier for users to identify patterns, correlations, and outliers.\r\nDecision-Making\r\nBy providing real-time insights, dashboards empower decision-makers to respond promptly to changes in data. Whether monitoring sales performance, tracking project milestones, or assessing financial health, dashboards facilitate informed decision-making.\r\nPerformance Monitoring\r\nDashboards enable organizations to track and monitor key performance indicators, helping identify areas of success and areas that require attention. This real-time visibility aids in maintaining a proactive approach to organizational goals.\r\nCustomization and Interactivity\r\nModern dashboards offer customization options, allowing users to tailor the display of data according to their preferences. Interactivity features, such as filtering and drill-down capabilities, enable users to explore specific aspects of the data for a comprehensive analysis.\r\nUser Engagement\r\nDashboards are designed to be user-friendly and visually appealing, promoting engagement with data. A well-crafted dashboard invites exploration and fosters a deeper connection with the underlying information.\r\nTypes of Dashboards:\r\nOperational Dashboards\r\nFocus on day-to-day operations, displaying real-time data relevant to ongoing processes. Commonly used in industries like manufacturing and logistics.\r\nStrategic Dashboards\r\nAlign with organizational strategies, providing a high-level overview of key performance indicators and long-term goals. Suitable for executive-level decision-makers.\r\nAnalytical Dashboards\r\nAllow users to delve into the details, exploring data sets and conducting in-depth analysis. Commonly used in data-driven industries such as finance and research.\r\nBasic procedure of creating a dashboard:\r\nDefine your audience and goals\r\nUnderstanding who will use the dashboard and what information they need to derive from it will guide you in creating a more effective and user-centric visualization.\r\nChoose your data\r\nRefers to the selection and preparation of the dataset that will be visualized on the dashboard.\r\nChoose your visualization\r\nThe choice of visualization depends on the nature of your data and the story you want to tell.\r\nKeep it simple. Make it as simple as possible for an easy understanding.\r\nGet feedback from your audience.\r\nExamples\r\nThe following are examples created using flexdashboard in r studio\r\nCar Falure Analysis i n US\r\n\r\nHR Dashboard\r\n\r\nFarm Dashboard\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:52:28+03:00"
    },
    {
      "path": "data_visualization.html",
      "title": "Data Visualization",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:52:33+03:00"
    },
    {
      "path": "Design.html",
      "title": "The Role of Experimental Designs in Modern Agriculture",
      "author": [
        {
          "name": "Julius Ndung'u",
          "url": {}
        }
      ],
      "date": "2024-06-05",
      "contents": "\r\nIntroduction\r\nIn the ever-evolving field of agriculture, the quest for higher yields,improved crop quality, and sustainable practices has been the catalyst for more Research. At the heart of these advancements lies a fundamental yet often overlooked tool: experimental design. Experimental designs in agriculture serve as the blueprint for systematic investigation,enabling researchers to test hypotheses, compare treatments, and draw reliable conclusions. Whether it’s optimizing fertilizer usage,developing pest-resistant crop varieties, or enhancing soil health,carefully crafted experimental designs are essential for translating scientific inquiry into practical solutions. This blog delves into the significance of experimental designs in agriculture, exploring how they drive innovation and shape the future of farming. Join me as I uncover the methodologies that help transform agricultural research from theoretical concepts into tangible benefits for farmers and consumers alike.\r\nSignificance of Experimental Designs in Agriculture.\r\nPrecision and Accuracy Agricultural experiments often involve studying the effects of various factors such as soil types, fertilizers, crop varieties and environmental conditions on crop yield, quality and other agronomic traits. By employing well-designed experimental designs, researchers can ensure that the results obtained are precise and accurate, reducing variability and enabling reliable comparisons betweentreatments.\r\nEfficiency Effective experimental designs maximize the use of available resources including land, labor and materials. By carefully planning the layout of experimental plots or treatment groups, researchers can achieve statistically efficient designs that yield reliable results withminimal waste.\r\nControl of Confounding Factors Agricultural systems are complex, with multiple factors influencing crop growth and performance. Experimental designs allow researchers to control for potential confounding factors by randomly assigning treatments to experimental units or by employing blocking and stratification techniques. This helps isolate the effects of specific treatments and reduces bias in the results.\r\nInference and Generalization Well-designed experiments provide a basis for making valid inferences and generalizations about the effects of treatments on crop performance. By ensuring the internal validity of the experiment through proper design and analysis, researchers can confidently extrapolate their findings to broader agricultural contexts,guiding farm management practices, policy decisions and future research directions.\r\nAdaptability to Field Conditions Agricultural experiments often take place in field settings, where environmental variability and logistical constraints pose challenges to data collection. Experimental designs tailored to field conditions, such as randomized complete block designs or split-plot designs, allow researchers to account for spatial variability and field heterogeneity, enhancing the relevance and applicability of the results to real-world agricultural scenarios.\r\nStatistical Analysis and Interpretation Agricultural research generates large volumes of data, requiring sophisticated statistical methods for analysis and interpretation. Properly designed experiments provide the necessary structure and replication for applying robust statistical techniques, such as analysis of variance (ANOVA), regression analysis and mixed-model approaches, to extract meaningful insights from the data.\r\nResource Allocation and Risk Management Agricultural production involves inherent risks related to weather variability, pest and disease outbreaks, market fluctuations and other factors. Experimental designs help farmers and agricultural stakeholders make informed decisions about resource allocation, risk management strategies, and technology adoption by providing evidence-based insights into the performance of different practices, inputs and technologies under varying conditions.\r\nHow Experimental Designs Drive Innovation and Shape the Future of Farming.\r\nOptimization of Inputs By conducting experiments to evaluate the effects of different inputs such as fertilizers, irrigation methodsand crop varieties on yield, quality, and resource use efficiency, farmers can optimize their use of inputs to maximize productivity while minimizing costs and environmental impact.\r\nAdaptation to Climate Change Experimental designs allow researchers to assess the resilience of crops and farming systems to climate change-induced stressors such as drought, heat, and pests. By identifying resilient crop varieties and management practices through experimentation, farmers can adapt their farming systems to changing climatic conditions and mitigate the negative impacts of climate change on agricultural productivity.\r\nEnhancement of Sustainability Experimentation plays a crucial role in developing and promoting sustainable farming practices that conserve soil, water and biodiversity while maintaining or improving yields. By testing innovative approaches such as conservation agriculture, agroforestry and organic farming through well-designed experiments, farmers can transition towards more sustainable production systems that enhance long-term productivity and environmental health.\r\nIntegration of Technology Experimental designs facilitate the evaluation of emerging technologies such as precision agriculture,remote sensing, and digital farming tools in real-world farming contexts. By conducting on-farm trials and field experiments,researchers and farmers can assess the efficacy and economic viability of new technologies and determine their potential to enhance efficiency,productivity and profitability in farming operations.\r\nEmpowerment of Farmer Decision-Making Through participatory research approaches and farmer-led experimentation, farmers become active participants in the innovation process, contributing their knowledge, experiences and preferences to the design and implementation of agricultural experiments. This participatory approach not only generates locally relevant solutions but also empowers farmers to make informed decisions about adopting new practices and technologies that best suit their needs and circumstances.\r\nResilience Building: Experimental designs enable the testing of diverse cropping systems, crop rotations, and agroecological principles to enhance the resilience of farming systems to biotic and abiotic stresses. By promoting biodiversity, soil health, and ecosystem services through experimentation, farmers can build resilient farming systems that are better equipped to withstand shocks and disturbances while maintaining productivity and profitability over the long term.\r\nKnowledge Sharing and Collaboration Experimental research fosters collaboration and knowledge sharing among researchers, extension agents,farmers and other stakeholders within the agricultural community. By disseminating research findings, best practices, and lessons learned from experiments through extension programs, farmer field schools, and digital platforms, innovative solutions and technologies can be scaled up and adopted more widely, driving collective learning and continuous improvement in farming practices.\r\nCommon Experimental Designs used in Agriculture\r\n1) Completely Randomized Design (CRD)\r\nLayout The whole field is divided into plots of similar shape and size. The number of plots is equal to the product of treatments and replications.These plots are then serially numbered.\r\nReplications There is no restriction on the number of replications in this design.The number of replications can vary from treatment to treatment.Normally, the number of replications for different treatments should be equal to get the estimates of treatment effects with same precision. The number of replication depends on the availability of experimental material and level of precision required.\r\nRandomization The randomization is done treatment wise with the help of random table.First random numbers equal to the number of plots are taken from the random table. From these random numbers each treatment is assigned numbers as per number of replications. Then random numbers of each treatment are allotted to the plots bearing the serial number similar to the random number.\r\nApplication\r\nSuitable for homogeneous fields where environmental conditions are uniformly spread.\r\nAdvantages\r\nSimplicity: Easy to set up and analyze.\r\nFlexibility:Suitable for any number of treatments.\r\nCost-effective: Requires fewer resources in terms of time and labor.\r\nDisadvantages\r\nAssumes Homogeneity: Effectiveness decreases in heterogeneous environments.\r\nA plot of Completely Randomized Design\r\n\r\n\r\n\r\nAnalysis of variance table for CRD\r\nSource of Variation\r\nDegrees of Freedom(DF)\r\nSum of squares(SS)\r\nMean Sum of Squares(MSS)\r\nF-value\r\nTreatments\r\nt-1\r\nSST\r\nMST\r\nMST/MSE\r\nError\r\nN-t\r\nSSE\r\nMSE\r\n\r\nTotal\r\nN-1\r\nSST+SSE\r\n\r\n\r\n2) Randomized Complete Block Design (RCBD)\r\n*Layout\r\nFirst the experimental field is divided into homogeneous groups equal to the number of replications. These homogeneous groups are known as blocks. Then each block is further divided into plots of similar shape and size equal to the number of treatments.\r\nReplications\r\nThere is no restriction on the number of replications. However, all the treatments should have equal number of replications.\r\nRandomization\r\nThe treatments are allotted to the plots in each block by a random process. Separate randomization is used in each block.\r\nApplication\r\nUsed when there is a need to control for variability in one direction, such as fertility gradients.\r\nAdvantages\r\nControl of Variability: Blocks account for variations,improving the precision of treatment comparisons.\r\nEfficient: Reduces experimental error.\r\nDisadvantages\r\nComplexity: More complex to set up and analyze compared to CRD. Block Size: Must ensure blocks are appropriate size and shape to account for variability.\r\nA plot of Randomized Complete Block Design (RCBD)\r\n\r\n\r\n\r\nAnalysis of variance Table for RCBD\r\nSource of Variation\r\nDegrees of Freedom(DF)\r\nSum of squares(SS)\r\nMean Sum of Squares(MSS)\r\nF-value\r\nTreatments\r\nt-1\r\nSST\r\nMST\r\nMST/MSE\r\nBlocks\r\nb-1\r\nSSB\r\nMSB\r\nMSB/MSE\r\nError\r\n(t-1)(b-1)\r\nSSE\r\nMSE\r\n\r\nTotal\r\ntb-1\r\nSST+SSB+SSE\r\n\r\n\r\nLatin Square Design (LSD)\r\nThe experimental design which simultaneously controls the fertility variation in two directions is called Latin square design (LSD). In other words, Latin square designs are adopted for eliminating the variation of two factors which are generally called rows and columns.\r\nLayout Treatments are arranged in a square grid where each treatment appears exactly once in each row and each column.\r\nApplication: Useful when controlling for two sources of variability, such as row and column effects.\r\nAdvantages\r\nEffectively controls variability in two directions.\r\nEfficient Use of Resources: Reduces the number of experimental units needed.\r\nDisadvantages\r\nComplexity: More complex to implement and analyze.\r\nLimited Treatments: Only practical for a limited number of treatments.\r\nA plot of Latin Square Design (LSD)\r\n\r\n\r\n\r\nAnalysis of variance Table for Latin Square Design\r\nSource of Variation\r\nDegrees of Freedom(DF)\r\nSum of squares(SS)\r\nMean Sum of Squares(MSS)\r\nF-value\r\nTreatments\r\nt-1\r\nSST\r\nMST\r\nMST/MSE\r\nRows\r\nt-1\r\nSSR\r\nMSR\r\nMSR/MSE\r\nColumns\r\nt-1\r\nSSC\r\nMSC\r\nMSC/MSE\r\nError\r\n(t-1)(t-2)\r\nSSE\r\nMSE\r\n\r\nTotal\r\n(t^2)-1\r\nSST+SSR+SSC+SSE\r\n\r\n\r\n\r\nt = Number of treatments (also the number of rows and columns)\r\n\r\nSplit-Plot Design\r\nThe experimental design in which experimental plots are split or divided into main plots, subplots and ultimate-plots is called split plot design (SPD). In this design several factors are studied simultaneously with different levels of precision. The factors are such that some of them require larger plots like irrigation, depth of ploughing and sowing dates, and others require smaller plots.\r\nStructure Main plots are divided into subplots, with one factor assigned to main plots and another factor to subplots.Application Useful when dealing with factors that are hard to change (main plots) and factors that are easy to change (subplots).\r\nAdvantages\r\nFlexibility: Allows testing of interactions between main plot and subplot factors.\r\nPractical: Reduces costs when one factor requires large plots or extensive management.\r\nDisadvantages\r\nComplexity: More complex statistical analysis required. Error Structure\r\nDifferent error terms for main plot and subplot factors.\r\nA plot of Split-Plot Design\r\nwith 4 whole plots, 2 sub plots per whole plot, and 4 reps in an RCBD arrangement. This in for a single location.\r\n\r\n\r\n\r\nAnalysis of variance Table for Split Plot Design\r\nSource of Variation\r\nDegrees of Freedom(DF)\r\nSum of squares(SS)\r\nMean Sum of Squares(MSS)\r\nF-value\r\nMain plot(A)\r\na-1\r\nSSA\r\nMSA\r\nMSA/MSE1\r\nsubplot(within main plots) Error (Whole plot)\r\na(b-1)\r\nSSE1\r\nMSE1\r\n\r\nSubplots(B)\r\nb-1\r\nSSB\r\nMSB\r\nMSB/MSE2\r\nInteraction(A*B)\r\n(a-1)(b-1)\r\nSSAB\r\nMSAB\r\n\r\nSubplots Errors\r\nab(r-1)\r\nSSE2\r\nMSE2\r\n\r\nTotals\r\nabr-1\r\nSST\r\n\r\n\r\n\r\na= Number of main plot treatments\r\n\r\n\r\nb= Number of subplot treatments\r\n\r\n\r\nr= Number of replicates\r\n\r\nReferences\r\n(“Running Experimental Designs” 2021; Morton and Montgomery 2011; Thyer 2012b, 2012a; Dykstra Miller and Blalock Jr. 2017; Murillo and Gezan 2023; Wright 2023)\r\n\r\n\r\n\r\nDykstra Miller, Alden, and H. M. Blalock Jr. 2017. “Logic of Causal Analysis: From Experimental to Nonexperimental Designs *.” In, 3–28. Routledge. https://doi.org/10.4324/9781315081670-2.\r\n\r\n\r\nMorton, Matthew, and Paul Montgomery. 2011. “Experimental and Quasi-Experimental Designs,” June. https://doi.org/10.1093/obo/9780195389678-0053.\r\n\r\n\r\nMurillo, Didier, and Salvador Gezan. 2023. “FielDHub: A Shiny App for Design of Experiments in Life Sciences.” https://CRAN.R-project.org/package=FielDHub.\r\n\r\n\r\n“Running Experimental Designs.” 2021. In, 123–54. SAGE Publications Ltd. https://doi.org/10.4135/9781529682779.n5.\r\n\r\n\r\nThyer, Bruce A. 2012a. “Pre-Experimental Research Designs.” In, 29–76. Oxford University Press. https://doi.org/10.1093/acprof:oso/9780195387384.003.0002.\r\n\r\n\r\n———. 2012b. “Quasi-Experimental Group Designs.” In, 77–106. Oxford University Press. https://doi.org/10.1093/acprof:oso/9780195387384.003.0003.\r\n\r\n\r\nWright, Kevin. 2023. “Desplot: Plotting Field Plans for Agricultural Experiments.” https://CRAN.R-project.org/package=desplot.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:52:51+03:00"
    },
    {
      "path": "East_Africa.html",
      "title": "East Africa Unveiled",
      "author": [
        {
          "name": "Ndung'u Julius",
          "url": {}
        }
      ],
      "date": "2023-11-03",
      "contents": "\r\n\r\nContents\r\nName and description of the dataset used in this blog.\r\nIntroduction\r\nPopulation density\r\nAgricultural Land (%)\r\nLand Area (Km2)\r\nArmed Forces Size\r\nBirth Rate\r\nCO2 Emissions\r\nForested Area (%)\r\nGasoline_Price\r\nLife Expectancy\r\nInfant Mortality\r\nMaternal Mortality Ratio\r\nMinimum Wage\r\nOut of Pocket Health Expenditure\r\nPopulation\r\nLabor Force Participation (%)\r\nTax levenue % of GDP\r\nTotal Tax Rate\r\nUnemployment Rate\r\nUrban Population\r\nSummary\r\nReferences\r\n\r\n\r\nName and description of the dataset used in this blog.\r\nName: Global Country Information Dataset 2023 (last update 4 months ago)\r\nA Comprehensive Dataset Empowering In-Depth Analysis and Cross-Country Insights\r\nlink: https://www.kaggle.com/datasets/nelgiriyewithana/countries-of-the-world-2023\r\nDescription\r\nThis comprehensive dataset provides a wealth of information about all countries worldwide, covering a wide range of indicators and attributes. It encompasses demographic statistics, economic indicators, environmental factors, healthcare metrics, education statistics, and much more. With every country represented, this dataset offers a complete global perspective on various aspects of nations, enabling in-depth analyses and cross-country comparisons.\r\nMy focus is on East Africa Countries\r\nIntroduction\r\nEast Africa, a region characterized by its diverse landscapes, rich cultural heritage, and dynamic socio-economic status. This dataset allows us to delve into the intricate details of East African countries, providing a holistic understanding of their demographic, economic, environmental, and healthcare landscapes. With a spotlight on key variables such as population density, economic indicators, healthcare metrics, and more, we aim to paint a vivid picture of the East African nations and facilitate insightful cross-country comparisons.\r\nEncompassing countries like Kenya, Tanzania, Uganda, Rwanda, Burundi, and South Sudan, the East African region is home to a tapestry of cultures, languages, and historical narratives. As I embark on this descriptive and visualization journey, I will leverage the wealth of information within the dataset to unravel the intricacies of each nation. From the bustling cities to the vast agricultural lands, from economic indicators shaping the growth trajectory to healthcare metrics influencing public well-being, our analysis aims to provide a nuanced understanding of East Africa. Lets get started\r\n\r\n\r\n\r\nPopulation density\r\n\r\n\r\n\r\n\r\nRegions with high population density often indicate crowded areas or areas with limited available land.Population density information is crucial for policymakers to plan for infrastructure development, housing, healthcare facilities, and other essential services.It helps in formulating strategies to manage urbanization, ensuring sustainable development and improving the overall quality of life for residents.\r\nRwanda and Burundi high population density can be attributed to limited available land.\r\nSouth sudan population is relatively sparse and is most concentrated in refuge zone.\r\n\r\nAgricultural Land (%)\r\n\r\n\r\n\r\n\r\nA higher percentage of land allocated to agriculture often indicates the economic significance of the agricultural sector within a country.\r\nCountries with a substantial portion of their land dedicated to agriculture may have economies heavily reliant on farming activities agriculture land is directly linked to domestic food security.\r\nMost of the economy of Eat Africa are heavly reliant of Agriculture.\r\n\r\nLand Area (Km2)\r\n\r\n\r\n\r\n\r\nLand area refers to the total extent of a geographical area measured in square kilometers.Countries with large land areas may have more diverse ecosystems and potential resource abundance.\r\n\r\nArmed Forces Size\r\n\r\n\r\n\r\n\r\nArmed forces size refers to the total number of active military personnel, including the army, navy, air force, and other branches.\r\nIt encompasses both professional soldiers and conscripted individuals, providing a comprehensive view of a country’s military manpower.the size of armed forces is critical for nation’s defense strategy and is determined by\r\n1)Population Size:\r\nThe need to maintain internal security and territorial integrity in a densely populated nation may drive the requirement for a larger military force.\r\n2)Geopolitical Context:\r\ngeopolitical position might contribute to the need for a larger military.\r\n3)Historical Factors:\r\nHistorical events, such as conflicts, wars, or periods of instability, can shape the size and structure of a country’s military.\r\n4)Economic Considerations:\r\nEconomic factors, such as the ability to allocate resources to defense, play a significant role in determining the size and capabilities of a military.\r\n5)Security Challenges:\r\nsecurity challenges, including insurgencies, terrorism, and ethno-religious conflicts may necessitate a larger military to address various security threats.\r\n6)Resource Allocation:\r\nThe decision on the size of the military is influenced by how a country allocates its resources among competing needs.\r\n\r\nBirth Rate\r\n\r\n\r\n\r\n\r\nA higher birth rate generally contributes to population growth, while a lower birth rate may result in population decline or stabilization.\r\nIt seems there is no much difference in the birth rate in all countries with the highest at 39 and the lowest at 29\r\n\r\nCO2 Emissions\r\n\r\n\r\n\r\n\r\nCO2 emissions refer to the release of carbon dioxide into the atmosphere, primarily as a result of human activities such as burning fossil fuels (coal, oil, and natural gas), industrial processes, deforestation, and certain agricultural practices.More developed countries are the greatter emission of CO2 in this case we have kenya leading and Burundi with the lowest.The increase in CO2 concentrations is a major driver of the observed rise in global temperatures, with cascading effects on weather patterns, sea levels, and ecosystems.The transition to cleaner energy sources, such as solar and wind power, is a key strategy to reduce CO2 emissions from the energy sector.\r\n\r\nForested Area (%)\r\n\r\n\r\n\r\n\r\nForest area refers to the total land area covered by trees with varying degrees of density and canopy cover.\r\nForests are crucial for maintaining ecological balance, supporting biodiversity, providing habitats for wildlife, and contributing to the overall health of the planet. They play a vital role in mitigating climate change by helping to regulate the global climate.Tanzania has the highest forest cover and Kenya has the lowest.\r\n\r\nGasoline_Price\r\n\r\n\r\n\r\n\r\nDifference in gasoline prices may be as a result of various factors including Exchange rates,taxes,government policies and subsidies,demand and supply,infrastructure and transportation costs and global oil prices.Gasoline prices plays a critical role on the cost of living, high gasoline prices can lead high cost of living\r\n\r\nLife Expectancy\r\n\r\n\r\n\r\n\r\nlife expectancy is critical to asses the economy of a country.A population with a higher life expectancy generally means a larger working-age population. This can contribute to a larger labor force, which, if effectively utilized, can lead to increased productivity and economic output. most of the countries in East Africa has life expectancy greater than 60, with Rwanda leading at 69\r\n\r\nInfant Mortality\r\n\r\n\r\n\r\n\r\nInfant mortality, defined as the death of a child before their first birthday, is an important indicator of a population’s health and the quality of healthcare services. It is usually expressed as the number of infant deaths per 1,000 live births. High infant mortality rates can be indicative of underlying health and socio-economic challenges Improving these factors can contribute to a reduction in infant mortality.Countrie with better health care report small cases e.g Rwanda, whereas those with poor access to health care and adverse socio economic condition have more cases.\r\n\r\nMaternal Mortality Ratio\r\n\r\n\r\n\r\n\r\nThis ratio is a crucial indicator in assessing the health and well-being of pregnant individuals and reflects the quality of maternal healthcare services.Maternal mortality can result from a range of causes, including complications during pregnancy, childbirth, and the postpartum period. Common causes include hemorrhage, infections, hypertensive disorders, and unsafe abortions.South Sudan has the highest number while Rwanda has the lowest\r\n\r\nMinimum Wage\r\n\r\n\r\n\r\n\r\nThe minimum wage is the lowest amount of compensation that employers are legally required to pay their employees for their work. Minimum wage levels vary widely from country to country and often within regions or states of a country. These rates are typically established by law and are intended to provide a basic standard of living for workers.\r\nseveral factors can influence the determination of minimum wage levels, including the cost of living, inflation rates, economic conditions, and government policies.\r\n\r\nOut of Pocket Health Expenditure\r\n\r\n\r\n\r\n\r\nOut-of-pocket health expenditure refers to the direct payments made by individuals at the time they receive healthcare services. These payments are made by individuals to healthcare providers and can include expenses such as co-payments, deductibles, and payments for services that are not covered by health insurance.\r\nThe extent of out-of-pocket health expenditure varies widely from country to country. In some countries, individuals may have comprehensive health coverage with minimal out-of-pocket expenses, while in others, individuals may bear a significant portion of their healthcare costs eg in our case South Sudan.\r\n\r\nPopulation\r\n\r\n\r\n\r\n\r\nPopulation is directly related to total land area. Countries with huge land areas have large population\r\n\r\nLabor Force Participation (%)\r\n\r\n\r\n\r\n\r\nIn many East African countries, agriculture is a significant contributor to employment. A large portion of the population is engaged in subsistence farming or agricultural-related activities. However, there is a growing recognition of the need for economic diversification to create more non-agricultural job opportunities.\r\n\r\nTax levenue % of GDP\r\n\r\n\r\n\r\n\r\nThe tax-to-GDP ratio is a key economic indicator that measures the proportion of a country’s economic output (Gross Domestic Product, GDP) that is collected as taxes. This ratio provides insights into the overall tax burden on the economy and the extent to which the government relies on taxation to fund public expenditures. Countries with good taxing system are associated with greater ratio.Recommended ratio should be above 15%.\r\n\r\nTotal Tax Rate\r\n\r\n\r\n\r\n\r\nThe total tax rate is a measure that reflects the total amount of taxes paid by a business as a percentage of its profits. It is commonly used to assess the overall tax burden on businesses and is a key indicator for understanding the tax environment in a particular country. The total tax rate includes not only corporate income taxes but also other taxes and contributions that businesses may be required to pay.This can influence the willingness of investor to invest in a particular country.\r\n\r\nUnemployment Rate\r\n\r\n\r\n\r\n\r\nThe unemployment rate is a key economic indicator that measures the percentage of the labor force that is unemployed and actively seeking employment. It provides insights into the health of the labor market and the overall economic conditions. South Sudan has the highest unemployment rate. This may be attributed to poor economic condition in the country.\r\n\r\nUrban Population\r\n\r\n\r\n\r\n\r\nUrban population refers to the number of people residing in urban areas, which are characterized by a higher population density and infrastructure development compared to rural areas.Urbanization is influenced by various factors, including industrialization, economic opportunities in urban centers, improved infrastructure, better access to education and healthcare, and changes in lifestyle preferences.\r\n\r\nSummary\r\nThe exploration of East African countries through comprehensive data analysis has unveiled a multifaceted view of the region. Covering a range of key variables such as population density, economic indicators, healthcare metrics, and more, the analysis has painted a vivid picture of the socio-economic landscapes of nations like Kenya, Tanzania, Uganda, Rwanda, Burundi, and South Sudan.\r\nThe dataset has allowed us to delve into diverse aspects, from the economic reliance on agriculture to the environmental impact reflected in CO2 emissions. We’ve observed variations in healthcare indicators, from life expectancy and infant mortality to maternal mortality ratios, shedding light on the health and well-being of the population.\r\nMoreover, social and economic factors such as minimum wage, out-of-pocket health expenditure, labor force participation, and tax rates have been scrutinized, offering insights into the economic conditions and government policies across the East African region. Urbanization trends, unemployment rates, and armed forces’ sizes have also contributed to our understanding of the broader dynamics at play.\r\nIn conclusion, this exploration underscores the complexity and diversity within the East African region. The analysis has not only provided a snapshot of the current state of these countries but also laid the groundwork for informed cross-country comparisons. The interplay of demographic, economic, and environmental factors highlights the intricate challenges and opportunities that each nation faces.\r\nAs we navigate through the data, it becomes evident that a holistic approach is essential for policymakers and stakeholders to address the unique needs of each country. Whether it’s planning for sustainable urbanization, improving healthcare systems, or formulating economic policies, a nuanced understanding of the data is paramount.\r\nThis journey into East Africa’s data landscape serves as a starting point for deeper discussions, further research, and informed decision-making. It is an invitation to explore the rich tapestry of cultures, challenges, and potentials that define this region. As we conclude this analysis, the hope is that these insights contribute to a more comprehensive understanding of East Africa and its trajectory in the global landscape.\r\nReferences\r\nUnited Nations Development Programme (UNDP). (2020). Human Development Report 2020. Retrieved from http://hdr.undp.org/sites/default/files/hdr2020.pdf\r\nWorld Bank. (2020). World Development Indicators. Retrieved from https://databank.worldbank.org/source/world-development-indicators\r\nWorld Health Organization (WHO). (2020). Global Health Observatory data repository. Retrieved from https://www.who.int/data/gho\r\nInternational Labour Organization (ILO). (2020). ILOSTAT database. Retrieved from https://ilostat.ilo.org/\r\nCentral Intelligence Agency (CIA). (2020). The World Factbook. Retrieved from https://www.cia.gov/the-world-factbook/\r\nAfrican Development Bank Group. (2020). African Economic Outlook. Retrieved from https://www.afdb.org/en/knowledge/publications/african-economic-outlook\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:53:16+03:00"
    },
    {
      "path": "Education.html",
      "title": "About Me",
      "author": [],
      "contents": "\r\nWho I Am\r\nHello! I’m Julius, a passionate data scientist with a strong background in statistics and economics. I specialize in transforming data into actionable insights that drive business decision and improves performance\r\nEducation\r\nUNIVERSITY OF EMBU (EMBU)\r\nBachelor of Economics and Statistics(2020,2024)\r\nCISCO ACADEMY\r\nCertificate in Data Analytics Essentials (2023)\r\nCisco Academy Certificate in Data Analytics Essentials (2023)\r\nIntroduction to Data Science\r\nCisco Academy Certificate in Introduction to Data Science (2023)\r\nVISIONDRILL\r\nProject Management Essential Training (2023)\r\nVisiondrill Project Management Essential Training (2023)\r\nSHORT COURSES\r\nData Analytic using Excel & SPSS\r\nGreat Learning (2023)\r\nUNIVERSITY OF EMBU STATISTICS CLUB (2021)\r\nR Programming\r\nGreat Learning (2023)\r\nUNIVERSITY OF EMBU STATISTICS CLUB (2021)\r\nFinancial Risk Analytics\r\nGreat Learning (2023)\r\nStatistical Methods for Decision Making\r\nGreat Learning(2023)\r\nBasics of Exploratory Data Analysis\r\nGreat Learning(2023)\r\nPredictive Modeling and Analytics - Regression\r\nGreat Learning(2023)\r\nProject Management\r\nGreat Learning(2023)\r\nNeural Network in R\r\nGreat Learning(2024)\r\nClustering in R\r\nGreat Learning(2024)\r\nMachine Learning Modelling\r\nGreat Learning(2024)\r\nProfessional Experience\r\nAttachment(May 2023,Aug 2023)\r\nKENYA AGRICULTURE AND LIVESTOCK RESEARCH ORGANIZATION\r\nFood Crop Research Center, Embu.\r\nKey achievements and Responsibilities\r\nAssisted in the collection, management and analysis of biometric\r\ndata for agricultural research projects.\r\nCollaborated with team to ensure the accuracy and integrity of\r\ndata, adhering to established protocols and standards.\r\nUtilized statistical software (e.g., Advanced Excel, SPSS, SAS\r\nand R) to clean and process data, enabling efficient data analysis\r\nand interpretation.\r\nContributed to the preparation of research reports and\r\npresentation by providing insights and visualization.\r\nGained practical experience in data handling, statistical analysis\r\nand research methodologies within an agriculture research setting.\r\nAttended data management meeting to discuss data protocols, new\r\nintegration systems and development\r\nReleased results and findings from tests, experiments and investigation to scientific communities to support future research engagements\r\nSkills and Expertise\r\nData Analysis Tools eg Excel, SQL, SPSS and R Programming\r\nVisualization Tools eg Tableau, ggplot2, Plotly\r\nStatistical Analysis eg hypothesis testing, regression analysis, descriptive statistics\r\nMachine Learning eg supervised learning and unsupervised learning\r\nDashboards Building\r\nEconometrics\r\nProject Management\r\nAttachment Recommendation Letter(2023)\r\nPersonal Interests\r\nwhen I’m not diving into data, I enjoy reading novels,Playing football,coding and community support services eg planting trees. Iam also passionate about data for social good and open source projects\r\nWhy Choose Me?\r\nI bring a blend of technical skills, analytical thinking and commitment to continuous learning. my goal is to leverage data to solve complex problem and helping organization to achieve its objectives\r\nActivities/Others\r\nLeadership Training (2022)\r\nEconomics and Statistics Representative(University of Embu Statistics Club Executive Committee) (2023)\r\nEmbu Town Clean-up Exercise (2022)\r\nUniversity of Embu Tree Planting Exercise (2024)\r\nTree Planting Activity In Memory of Victims of Road Accidents (2022)\r\nTree Planting Activity (University of Embu 2021 Long Rains Tree Planting Exercise) (2021)\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:53:20+03:00"
    },
    {
      "path": "gdp.html",
      "title": "Will Kenyan GDP Growth Reach 10% by 2030?",
      "author": [
        {
          "name": "Julius Ndung'u",
          "url": {}
        }
      ],
      "date": "2024-04-18",
      "contents": "\r\nAs Kenya marches forward into the future, the question of its economic trajectory looms large on the national agenda.\r\nWith ambitious development goals outlined in the Vision 2030 agenda, the country aspires to achieve sustained and inclusive economic growth that uplifts the lives of its citizens.\r\nAt the heart of this vision lies the GDP growth rate, a key indicator of economic health and prosperity.\r\nIn recent years, Kenya has made significant strides in its economic journey, with notable achievements in sectors such as agriculture, manufacturing, and services.\r\nHowever, as the nation sets its sights on the next decade, the question arises: will Kenya achieve a GDP growth rate of 10 percent by 2030?\r\nThis blog seeks to explore this pressing question by delving into the realm of time series analysis.\r\nBy leveraging historical GDP data and employing sophisticated forecasting techniques, I aim to unravel the trends, patterns, and potential future trajectories of Kenya’s economic growth.\r\n\r\n\r\n\r\nTrend in Kenya GDP Growth Rate\r\n1990s - Early 2000s\r\nIn the early 1990s, Kenya embarked on economic reforms aimed at liberalizing the economy and attracting foreign investment.\r\nHowever, the country faced challenges such as political instability and corruption, which hampered economic growth.Despite these challenges, the late 1990s saw a period of moderate GDP growth driven by sectors like agriculture, manufacturing, and services.\r\nPolitical reforms and improved governance in the late 1990s and early 2000s contributed to a more favorable investment climate, supporting economic expansion.\r\nMid-2000s - Pre-Financial Crisis (2005-2007)\r\nThe mid-2000s witnessed a period of relatively robust GDP growth, fueled by increased investment in infrastructure, telecommunications, and financial services.\r\nGovernment initiatives to promote private sector development and attract foreign direct investment (FDI) also supported economic expansion.\r\nKenya’s economy benefited from favorable global conditions, including high commodity prices and strong demand for exports.\r\nGlobal Financial Crisis (2008-2009)\r\nThe global financial crisis of 2008-2009 had a significant impact on Kenya’s economy, leading to a slowdown in GDP growth.Reduced demand for exports, declining remittances, and disruptions in global trade negatively affected key sectors like agriculture, tourism, and manufacturing.\r\nThe crisis exposed vulnerabilities in Kenya’s financial sector and highlighted the importance of diversifying the economy and strengthening resilience to external shocks.\r\nThe political instability that erupted in Kenya in 2007 and 2008, following disputed presidential elections, severely impacted the country’s GDP growth trajectory.\r\nWidespread violence and ethnic clashes paralyzed economic activities, disrupted supply chains, and caused significant damage to infrastructure and businesses.Investor confidence plummeted, leading to capital flight and a contraction in GDP growth\r\nPost-Crisis Recovery (2010-2013)\r\nFollowing the global financial crisis, Kenya experienced a period of recovery and resumed GDP growth, supported by government stimulus measures and renewed investor confidence.\r\nInfrastructure development projects, such as the construction of roads, ports, and energy facilities, played a crucial role in driving economic activity and creating employment opportunities.\r\nKenya’s vibrant services sector, including telecommunications, banking, and information technology, emerged as a key driver of growth during this period.\r\n2010s - Recent Years (2014-2023):\r\nThe 2010s saw mixed economic performance, with periods of strong growth interspersed with slowdowns and challenges.\r\nFactors such as political uncertainty, security concerns, and adverse weather conditions (e.g., droughts) posed headwinds to economic expansion.Nevertheless, Kenya continued to attract investment in sectors like real estate, energy, and infrastructure, supported by government initiatives to improve the business environment and promote entrepreneurship.\r\n\r\n\r\n\r\nUsing Holt-Winters Method for GDP Growth Rate Forecasting\r\nTo forecast Kenya’s GDP growth rate up to 2030, I chose the Holt-Winters method, a powerful and flexible time series forecasting technique. The Holt-Winters method, also known as the Exponential Smoothing State Space Model (ETS), is adept at capturing complex patterns in data, including level and trend components.\r\nWhy Holt-Winters?\r\nTrend Detection: Our GDP growth rate data shows a clear trend over time, which is crucial for making accurate forecasts. The Holt-Winters method effectively captures and extrapolates this trend.\r\nFlexibility: This method can be adapted to data with or without seasonal patterns. Since our GDP data lacks seasonality but exhibits a trend, we can disable the seasonal component (gamma) and still leverage the method’s strengths.\r\nSimplicity and Interpretability: The Holt-Winters method is straightforward to implement and interpret, making it easier to explain the forecast results and underlying assumptions.\r\nProven Robustness: Widely used in economic forecasting, the Holt-Winters method is known for its robustness and reliability across various types of time series data.\r\nModel Fitting and Forecasting\r\nBy fitting the Holt-Winters model to our historical GDP growth rate data and forecasting future values, we aim to provide reliable projections that inform economic planning and policy-making. The model captures the underlying trend, allowing us to make informed predictions about Kenya’s economic growth trajectory up to 2030.\r\n\r\nHolt-Winters exponential smoothing with trend and without seasonal component.\r\n\r\nCall:\r\nHoltWinters(x = gdp_ts, gamma = F)\r\n\r\nSmoothing parameters:\r\n alpha: 0.5807826\r\n beta : 0.2718869\r\n gamma: FALSE\r\n\r\nCoefficients:\r\n       [,1]\r\na 5.3704952\r\nb 0.2467251\r\n\r\nPractical Interpretation\r\nLevel (a = 5.3704952): The current GDP growth rate is around 5.37%. This is the baseline value from which future growth is projected.\r\nTrend (b = 0.2467251): The GDP growth rate is projected to increase by approximately 0.25% per year. This indicates a positive growth trend in the GDP growth rate.\r\nWhy These Parameters Matter\r\nAlpha = 0.5807826: The relatively high alpha value means the model is responsive to recent changes in GDP growth rate, allowing it to quickly adapt to new data.\r\nBeta = 0.2718869: The moderate beta value indicates a stable trend estimation. The trend component is updated cautiously, which prevents overreacting to short-term fluctuations.\r\nGamma = FALSE: By setting gamma to FALSE, the model focuses solely on capturing the trend and level, which suits the nature of your data (no seasonality).\r\nPrediction\r\n\r\n\r\n\r\n2024:\r\nThe estimated GDP growth rate for 2024 is 5.62%.\r\n2025:\r\nThe estimated GDP growth rate for 2025 is 5.86%.\r\n2026:\r\nThe estimated GDP growth rate for 2026 is 6.11%.\r\n2027:\r\nThe estimated GDP growth rate for 2027 is 6.36%.\r\n2028:\r\nThe estimated GDP growth rate for 2028 is 6.60%.\r\n2029:\r\nThe estimated GDP growth rate for 2029 is 6.85%.\r\n2030:\r\nThe estimated GDP growth rate for 2030 is 7.10%.\r\nLimitation of the Model\r\nWhile the Holt-Winters method is a powerful tool for time series forecasting, it’s important to acknowledge its limitations:\r\nAssumption of Stationarity: The Holt-Winters method assumes that the time series data is stationary, meaning that its statistical properties such as mean and variance do not change over time. In reality, economic data like GDP growth rates often exhibit non-stationarity due to various factors such as economic cycles, policy changes, and external shocks.\r\nLimited Incorporation of External Factors: The model primarily relies on historical data to make forecasts and may not adequately capture the impact of external factors such as geopolitical events, changes in government policies, or technological advancements. These factors can significantly influence economic trends but are not explicitly accounted for in the Holt-Winters framework.\r\nSensitivity to Initial Conditions: The accuracy of forecasts produced by the Holt-Winters method can be sensitive to the initial values of the smoothing parameters (alpha, beta, and gamma). Choosing inappropriate initial values may result in suboptimal forecasts, especially for longer-term projections.\r\nInability to Handle Sudden Changes: The Holt-Winters method may struggle to adapt to sudden and unexpected changes in the data, such as economic recessions or financial crises. Since it relies heavily on past observations, it may take time for the model to adjust to new trends or patterns, leading to delayed or inaccurate forecasts during periods of volatility.\r\nDifficulty in Interpreting Seasonality: While the Holt-Winters method can accommodate seasonal patterns in the data, interpreting and modeling seasonality accurately can be challenging, especially for longer time series with irregular or non-traditional seasonal patterns.\r\nRisk of Overfitting: Like any forecasting model, there is a risk of overfitting the data, especially if the model is too complex or if there is noise in the data. Overfitting occurs when the model captures random fluctuations or noise in the data rather than underlying patterns, leading to poor performance on new, unseen data.\r\nLimited Forecast Horizon: Forecast accuracy tends to decrease as the forecast horizon extends further into the future. This is because the uncertainty associated with longer-term forecasts increases, and the model may not capture complex dynamics or structural changes that occur over longer time periods.\r\nHomogeneous Treatment of Data: The Holt-Winters method treats all data points equally in terms of their contribution to the forecast, which may not always be appropriate, especially if there are outliers or anomalies in the data that need to be weighted differently.\r\nAcknowledging these limitations is essential for ensuring the appropriate application and interpretation of the Holt-Winters method in forecasting GDP growth rates or any other time series data. It’s often beneficial to complement the Holt-Winters method with other forecasting techniques and incorporate domain knowledge to enhance the robustness of forecasts.\r\nConclusion\r\nIn conclusion, our analysis utilizing the Holt-Winters exponential smoothing method provides valuable insights into the projected trajectory of Kenya’s GDP growth rate up to 2030. The forecasted GDP growth rates demonstrate a positive trend, with estimates increasing steadily from 5.62% in 2024 to 7.10% in 2030, based on the point forecasts. However, it’s crucial to interpret these forecasts within the context of the accompanying confidence intervals, which indicate the level of uncertainty surrounding the projections.\r\n(PISTORESI and RINALDI 2014; Jaunky, Vishal C. 2013; Murach and Wagner 2019; Murach et al. 2020)\r\n\r\n\r\n\r\nJaunky, Vishal C. 2013. “Democracy and Economic Growth in Sub-Saharan Africa: A Panel Data Approach.” ETH Zurich. https://doi.org/10.3929/ETHZ-B-000059047.\r\n\r\n\r\nMurach, Michael, and Helmut Wagner. 2019. The Effects of External Shocks on the Business Cycle in China: A Structural Change Perspective. MyCoRe Community. https://doi.org/10.18445/20200219-094751-1.\r\n\r\n\r\nMurach, Michael, Helmut Wagner, Jungsuk Kim, and Donghyun Park. 2020. Trajectories to High Income: Comparing the Growth Dynamics in China, Korea, and Japan with Cointegrated VAR Models. MyCoRe Community. https://doi.org/10.18445/20200206-102020-0.\r\n\r\n\r\nPISTORESI, Barbara, and Alberto RINALDI. 2014. “Capital Inflows, Current Accounts and Investment Cycle in Italy: 1861-1913.” https://doi.org/10.25431/11380_1190582.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:53:31+03:00"
    },
    {
      "path": "Happiness.html",
      "title": "Happiness data analysis",
      "description": "A look at the Happiness Report 2023\n",
      "author": [
        {
          "name": "Ndung'u Julius",
          "url": {}
        }
      ],
      "date": "2023-12-02",
      "contents": "\r\n\r\nContents\r\nDefinition of terms\r\nIntroduction\r\nDistribution of hapinness score\r\nRelationship Analysis:\r\nWealth\r\n\r\nLife expectancy\r\nSocial Support\r\nFreedom to make life choices.\r\nGenerosity\r\nCorruption\r\nTrend\r\nModelling\r\nSpecial cases\r\nReference\r\n\r\nDefinition of terms\r\nHappy is defined as having a feeling arising from consciousness of well-being or enjoyment; enjoying good of any kind, such as comfort, peace or tranquility.\r\nHappiness is defined as the emotion of being happy\r\nWealth\r\nIt refers to the abundance of valuable resources or possessions that an individual, community, or nation possesses. It encompasses assets, income, and material possessions that contribute to financial well-being and economic prosperity.\r\nLife expectancy\r\nIs the average number of years a person is expected to live, based on statistical measures and factors such as health, medical advancements, and overall well-being. It serves as a key indicator of a population’s health and the quality of living conditions.\r\nSocial Support\r\nIt represents the network of relationships and assistance from family, friends, and communities that individuals can rely on during times of need. It plays a crucial role in mental and emotional well-being, providing a sense of belonging, connection, and assistance.\r\nFreedom\r\nFreedom denotes the state of being able to act, choose, and live without undue constraints or limitations. It encompasses political liberties, personal autonomy, and the absence of coercion, reflecting the capacity of individuals to make choices in various aspects of their lives.\r\nGenerosity\r\nIt refers to the willingness and readiness to share one’s resources, time, or assistance with others without expecting something in return. It involves acts of kindness, philanthropy, and a compassionate disposition towards contributing to the well-being of others.\r\nIntroduction\r\nIn a rapidly changing world, understanding the factors that contribute to global happiness has become increasingly important. The World Happiness Report, an annual publication by the United Nations, provides a comprehensive overview of happiness levels across countries, accompanied by various contributing factors. I aims to delve into this rich dataset, employing the power of R for insightful analysis and visualization.\r\n\r\n\r\n\r\nSummary descriptive\r\n\r\n   Happiness         wealth       life_expectancy Country.name      \r\n Min.   :1.281   Min.   : 5.527   Min.   : 6.72   Length:2199       \r\n 1st Qu.:4.647   1st Qu.: 8.500   1st Qu.:59.12   Class :character  \r\n Median :5.432   Median : 9.499   Median :65.05   Mode  :character  \r\n Mean   :5.479   Mean   : 9.390   Mean   :63.29                     \r\n 3rd Qu.:6.309   3rd Qu.:10.373   3rd Qu.:68.50                     \r\n Max.   :8.019   Max.   :11.664   Max.   :74.47                     \r\n                 NA's   :20       NA's   :54                        \r\n      year      Social.support   Freedom.to.make.life.choices\r\n Min.   :2005   Min.   :0.2280   Min.   :0.2580              \r\n 1st Qu.:2010   1st Qu.:0.7470   1st Qu.:0.6562              \r\n Median :2014   Median :0.8360   Median :0.7700              \r\n Mean   :2014   Mean   :0.8107   Mean   :0.7479              \r\n 3rd Qu.:2018   3rd Qu.:0.9050   3rd Qu.:0.8590              \r\n Max.   :2022   Max.   :0.9870   Max.   :0.9850              \r\n                NA's   :13       NA's   :33                  \r\n   Generosity       Perceptions.of.corruption Positive.affect \r\n Min.   :-0.33800   Min.   :0.0350            Min.   :0.1790  \r\n 1st Qu.:-0.11200   1st Qu.:0.6880            1st Qu.:0.5720  \r\n Median :-0.02300   Median :0.8000            Median :0.6630  \r\n Mean   : 0.00009   Mean   :0.7452            Mean   :0.6521  \r\n 3rd Qu.: 0.09200   3rd Qu.:0.8690            3rd Qu.:0.7380  \r\n Max.   : 0.70300   Max.   :0.9830            Max.   :0.8840  \r\n NA's   :73         NA's   :116               NA's   :24      \r\n Negative.affect \r\n Min.   :0.0830  \r\n 1st Qu.:0.2080  \r\n Median :0.2610  \r\n Mean   :0.2715  \r\n 3rd Qu.:0.3230  \r\n Max.   :0.7050  \r\n NA's   :16      \r\n\r\nSome key information from the summary statistic\r\nHappiness Scores:\r\nThe range of happiness scores spans from approximately 1.281 to 8.019.\r\nThe average (mean) happiness score is around 5.479, and the median is 5.432.\r\nThe distribution of happiness scores seems to be somewhat positively skewed, as the mean is slightly higher than the median.\r\nLife Expectancy:\r\nThe range of life expectancy is from 6.72 to 74.47.\r\nThe distribution of life expectancy appears to be right-skewed, with a median (65.05) lower than the mean (63.29).\r\nWealth:\r\nThe log GDP per capita(wealth) ranges from 5.527 to 11.664.\r\nThe mean log GDP per capita(wealth) is 9.390, with a median of 9.499.\r\nSocial Support, Freedom, and Generosity:\r\nSocial support ranges from 0.228 to 0.9870.\r\nFreedom to make life choices ranges from 0.258 to an 0.9850.\r\nGenerosity ranges from -0.338 to 0.7.\r\n*Time Period:\r\nThe data covers the years from 2005 to 2022.\r\nThe median year in the dataset is 2014.\r\nDistribution of hapinness score\r\n\r\n\r\n\r\n\r\nfrom the histogram above we confirm the positive skew as indicated earlier in our summary statistics. This suggests that there are relatively more countries with lower happiness scores and fewer countries with very high happiness scores.\r\n\r\nRelationship Analysis:\r\nWealth\r\n\r\n\r\n\r\n\r\nAs wealth increases the level of happiness also increases. Countries with higher average incomes reports higher average happiness scores. As individuals and societies achieve higher income levels, they can afford better healthcare, education, and living conditions, contributing to an overall improvement in life satisfaction.\r\n\r\nLife expectancy\r\n\r\n\r\n\r\n\r\nLonger life expectancies are associated with better healthcare, improved living conditions, and access to resources that contribute to well-being.\r\nIndividuals in societies with better health outcomes may feel more confident about their long-term well-being, contributing to higher reported levels of happiness. Also increased life expectancy provides individuals with more time to pursue and achieve their life goals. This sense of purpose and accomplishment can positively impact happiness levels.\r\n\r\nSocial Support\r\n\r\n\r\n\r\n\r\nSocial support fosters a sense of belonging, which is a fundamental psychological need. Feeling connected to others and being part of a community or network can contribute to a deeper sense of purpose and happiness. therefore as social support increasesthe more happier people are.\r\n\r\nFreedom to make life choices.\r\n\r\n\r\n\r\n\r\nHaving the freedom to make life choices provides individuals with a sense of control over their lives. This sense of agency is associated with higher levels of self-esteem and life satisfaction.\r\n\r\nGenerosity\r\n\r\n\r\n\r\n\r\nCountrie with more generous people also have high happines ranking\r\n\r\nCorruption\r\n\r\n\r\n\r\nTrend\r\n\r\n\r\n\r\n\r\nHappiness level in 2005 were very high.This might be attributed to:\r\nEconomic Conditions:\r\nThe mid-2000s saw a period of global economic growth, with several countries experiencing positive economic indicators. The world economy was recovering from the early 2000s recession, and many regions were witnessing economic expansion.\r\nGlobal Stability:\r\nThe world was relatively stable in terms of geopolitical events compared to some periods before and after. There were no major world wars or large-scale conflicts that directly involved many nations.\r\nTechnological Advancements:\r\nThe mid-2000s marked the rise of technology and the internet. The introduction of social media platforms, such as Facebook and YouTube, began to reshape communication and information sharing globally.\r\n\r\nModelling\r\nRegression Analysis:\r\n\r\n\r\n \r\n\r\n\r\nHappiness\r\n\r\n\r\nPredictors\r\n\r\n\r\nEstimates\r\n\r\n\r\nCI\r\n\r\n\r\np\r\n\r\n\r\n(Intercept)\r\n\r\n\r\n-2.74\r\n\r\n\r\n-3.08 – -2.39\r\n\r\n\r\n<0.001\r\n\r\n\r\nwealth\r\n\r\n\r\n0.40\r\n\r\n\r\n0.35 – 0.44\r\n\r\n\r\n<0.001\r\n\r\n\r\nlife expectancy\r\n\r\n\r\n0.03\r\n\r\n\r\n0.02 – 0.03\r\n\r\n\r\n<0.001\r\n\r\n\r\nSocial support\r\n\r\n\r\n1.82\r\n\r\n\r\n1.50 – 2.14\r\n\r\n\r\n<0.001\r\n\r\n\r\nFreedom to make lifechoices\r\n\r\n\r\n0.38\r\n\r\n\r\n0.14 – 0.62\r\n\r\n\r\n0.002\r\n\r\n\r\nGenerosity\r\n\r\n\r\n0.35\r\n\r\n\r\n0.19 – 0.51\r\n\r\n\r\n<0.001\r\n\r\n\r\nPerceptions of corruption\r\n\r\n\r\n-0.70\r\n\r\n\r\n-0.86 – -0.54\r\n\r\n\r\n<0.001\r\n\r\n\r\nPositive affect\r\n\r\n\r\n2.31\r\n\r\n\r\n2.02 – 2.61\r\n\r\n\r\n<0.001\r\n\r\n\r\nNegative affect\r\n\r\n\r\n-0.01\r\n\r\n\r\n-0.35 – 0.32\r\n\r\n\r\n0.931\r\n\r\n\r\nObservations\r\n\r\n\r\n1958\r\n\r\n\r\nR2 / R2 adjusted\r\n\r\n\r\n0.780 / 0.779\r\n\r\n\r\n\r\nThe model has a strong overall fit (Adjusted R-squared = 0.779), indicating that these variables collectively explain approximately 77.9% of the variance in happiness scores. Wealth, positive affect, and social support have the most substantial positive influences, while perceptions of corruption have a negative impact.\r\n\r\nRegional Analysis:\r\n\r\n\r\n\r\nSpecial cases\r\nVenezuela\r\n\r\n\r\n\r\n\r\nThe wealth of venezuela drops drastically from 2012\r\nThe drastic drop in Venezuela’s wealth from 2012 is primarily attributed to the country’s heavy dependence on oil exports. Venezuela, a major oil producer, faced a significant decline in global oil prices, impacting its main source of revenue. Economic mismanagement, corruption, and unsustainable policies exacerbated the crisis, leading to hyperinflation, economic collapse, and a decline in living standards. Political instability and social unrest further contributed to the severe economic downturn, marking a period of economic and humanitarian crisis in the country.\r\n\r\nIndia\r\n\r\n\r\n\r\n\r\nHappiness declined as life expectancy increases\r\n\r\nFinland and Denmark\r\nFinland and Denmark are consistently ranked as some of the happiest countries in the world according to various global happiness reports. Several factors contribute to their high happiness rankings:\r\nHigh-Quality Healthcare and Education:\r\nAccessible and high-quality healthcare and education are essential components of a good life. Both Finland and Denmark invest heavily in these areas, ensuring that citizens have access to excellent healthcare services and education.\r\nWork-Life Balance:\r\nWork-life balance\r\nThe work-life balance is highly valued in these countries. Policies such as flexible working hours, parental leave, and vacation time contribute to a healthier balance between work and personal life.\r\nTrust in Government and Institutions:\r\nHigh levels of trust in government and public institutions are observed in Finland and Denmark. Citizens tend to have confidence in their political leaders and believe in the effectiveness and fairness of public policies.\r\nSafety and Low Crime Rates:\r\nThe Nordic countries are known for their safety and low crime rates. A sense of security contributes to overall happiness and well-being.\r\nCultural Factors:\r\nCultural factors, including a strong sense of community, equality, and a focus on personal fulfillment rather than material wealth, contribute to the happiness of residents in these countries.\r\nTax as a percentage of GDP\r\n\r\n\r\n\r\n\r\nIn the two countries citizen pays more tax enabling the government to have enough resources to provide public goods such as Education and Health care.\r\n\r\nReference\r\nWorld Happiness Report. (2023). Retrieved from https://worldhappiness.report/\r\nHelliwell, J. F., Layard, R., Sachs, J. (Eds.). (2023). World Happiness Report 2023. New York: Sustainable Development Solutions Network.\r\nSustainable Development Solutions Network. (2023). World Happiness Report Data. Retrieved from https://worldhappiness.report/ed/2023/\r\nGallup World Poll. (2023). Retrieved from https://www.gallup.com/analytics/350686/world-poll.aspx\r\nUnited Nations. (2023). World Happiness Report 2023: Key Findings and Data. Retrieved from https://www.un.org/sustainabledevelopment/happiness/\r\nHelliwell, J. F., Layard, R., Sachs, J. D., Aknin, L. B., De Neve, J.-E., & Wang, S. (Eds.). (2023). World Happiness Report 2023 (11th ed.). Sustainable Development Solutions Network.\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:54:16+03:00"
    },
    {
      "path": "House_prices.html",
      "title": "House price Prediction Model Using R Software",
      "author": [
        {
          "name": "Julius Ndung'u",
          "url": {}
        }
      ],
      "date": "2024-02-20",
      "contents": "\r\n\r\nContents\r\nIntroduction\r\nVariables in the dataset\r\nRequired packages\r\nImporting the dataset\r\nData Pre-processing\r\nLooking for dublicate\r\nLooking for incomplete cases\r\nChanging data types\r\n\r\nBasic Exploratory Data Analysis\r\nExplanation\r\nPrice:\r\nArea:\r\nBedrooms:\r\nBathrooms\r\nStories:\r\nMainroad:\r\nGuestroom\r\nBasement\r\nHotwaterheating\r\nAir conditioning\r\nPreferred area\r\nFurnishing status:\r\n\r\nHistogram of price\r\nTransformation of our dependent variable\r\nFeature selection\r\nSplitting the Data\r\nMultiple linear Regression\r\nInterpretation of Significant variables\r\nChecking the model performance\r\nDiagnostic Tests\r\n1)Auto correlation\r\n2) Multcolinearity\r\n3) Homoscedasticity\r\n4) Normality test\r\n5) Outliers\r\n\r\nPredicting Using The Model\r\nLimitation of my model\r\nDatasource:\r\n\r\n\r\nIntroduction\r\nIn today’s dynamic real estate market, accurately predicting house prices is crucial for both buyers and sellers to make informed decisions. With the ever-changing landscape of property values influenced by various factors such as location, size, amenities, and market trends, leveraging data-driven insights becomes imperative.\r\nThis project aims to develop a predictive model for house prices utilizing machine learning techniques. By analyzing a comprehensive dataset encompassing key features like house area, number of bedrooms and bathrooms, amenities, and location attributes, the model seeks to forecast the selling price of residential properties.\r\nThe dataset comprises a diverse range of properties, each characterized by its unique set of features and corresponding market values. Leveraging advanced regression algorithms, I aim to uncover patterns and relationships within the data to accurately predict house prices.\r\nVariables in the dataset\r\nPrice: This variable represents the selling price of a house in dollars. It is measured as an integer (e.g., 13300000, 12250000) and is the target variable in the predictive model, as we aim to predict house prices based on other features.\r\nArea: This variable represents the area of the house in square feet. It is measured as an integer (e.g., 7420, 8960) and provides information about the size of the property.\r\nBedrooms: This variable represents the number of bedrooms in the house. It is measured as an integer (e.g., 4, 3) and provides information about the accommodation capacity of the property.\r\nBathrooms: This variable represents the number of bathrooms in the house. It is measured as an integer (e.g., 2, 4) and provides information about the sanitary facilities of the property.\r\nStories: This variable represents the number of stories or floors in the house. It is measured as an integer (e.g., 3, 4) and provides information about the vertical structure of the property.\r\nMainroad: This variable is categorical and indicates whether the house is located on a main road or not. It takes on binary values, such as “yes” or “no,” and provides information about the accessibility and potential traffic noise of the property.\r\nGuestroom: This variable is categorical and indicates whether the house has a guestroom or not. It takes on binary values, such as “yes” or “no,” and provides information about additional accommodation features of the property.\r\nBasement: This variable is categorical and indicates whether the house has a basement or not. It takes on binary values, such as “yes” or “no,” and provides information about additional storage or living space of the property.\r\nHotwaterheating: This variable is categorical and indicates whether the house has hot water heating or not. It takes on binary values, such as “yes” or “no,” and provides information about the heating system of the property.\r\nAirconditioning: This variable is categorical and indicates whether the house has air conditioning or not. It takes on binary values, such as “yes” or “no,” and provides information about the cooling system of the property.\r\nParking: This variable represents the number of parking spaces available with the house. It is measured as an integer (e.g., 2, 3) and provides information about parking facilities for residents or visitors.\r\nPrefarea: This variable is categorical and indicates whether the house is located in a preferred area or not. It takes on binary values, such as “yes” or “no,” and provides information about the desirability or popularity of the property’s location.\r\nFurnishingstatus: This variable is categorical and indicates the furnishing status of the house. It can take on multiple values, such as “furnished,” “semi-furnished,” or “unfurnished,” and provides information about the interior condition and amenities of the property.\r\nRequired packages\r\n\r\n\r\nlibrary(tidyverse)# for data manipulation\r\nlibrary(Boruta)# for feature selection\r\nlibrary(rsample)# for dividing my data into training and testing\r\nlibrary(performance)# evaluating the performance of the model\r\nlibrary(lava)\r\nlibrary(caret) #for data partitioning\r\nlibrary(DT)\r\n\r\n\r\nImporting the dataset\r\n\r\n\r\nhouse <- read_csv(\"Housing.csv\",col_names = T)\r\n\r\n\r\nData Pre-processing\r\nLooking for dublicate\r\n\r\n\r\nhouse %>% duplicated() %>% unique()\r\n\r\n[1] FALSE\r\n\r\n\r\nThere is no dublicate\r\n\r\nLooking for incomplete cases\r\n\r\n\r\nhouse %>% filter(!complete.cases(.))\r\n\r\n# A tibble: 0 × 13\r\n# ℹ 13 variables: price <dbl>, area <dbl>, bedrooms <dbl>,\r\n#   bathrooms <dbl>, stories <dbl>, mainroad <chr>, guestroom <chr>,\r\n#   basement <chr>, hotwaterheating <chr>, airconditioning <chr>,\r\n#   parking <dbl>, prefarea <chr>, furnishingstatus <chr>\r\n\r\nChanging data types\r\n\r\n\r\nhouse$mainroad <- factor(house$mainroad)\r\nhouse$guestroom <- factor(house$guestroom)\r\nhouse$basement <- factor(house$basement)\r\nhouse$hotwaterheating <- factor(house$hotwaterheating)\r\nhouse$airconditioning <- factor(house$airconditioning)\r\nhouse$prefarea <- factor(house$prefarea)\r\nhouse$furnishingstatus <- factor(house$furnishingstatus)\r\n\r\n\r\nBasic Exploratory Data Analysis\r\n\r\n\r\nhouse %>% summary()\r\n\r\n     price               area          bedrooms       bathrooms    \r\n Min.   : 1750000   Min.   : 1650   Min.   :1.000   Min.   :1.000  \r\n 1st Qu.: 3430000   1st Qu.: 3600   1st Qu.:2.000   1st Qu.:1.000  \r\n Median : 4340000   Median : 4600   Median :3.000   Median :1.000  \r\n Mean   : 4766729   Mean   : 5151   Mean   :2.965   Mean   :1.286  \r\n 3rd Qu.: 5740000   3rd Qu.: 6360   3rd Qu.:3.000   3rd Qu.:2.000  \r\n Max.   :13300000   Max.   :16200   Max.   :6.000   Max.   :4.000  \r\n    stories      mainroad  guestroom basement  hotwaterheating\r\n Min.   :1.000   no : 77   no :448   no :354   no :520        \r\n 1st Qu.:1.000   yes:468   yes: 97   yes:191   yes: 25        \r\n Median :2.000                                                \r\n Mean   :1.806                                                \r\n 3rd Qu.:2.000                                                \r\n Max.   :4.000                                                \r\n airconditioning    parking       prefarea        furnishingstatus\r\n no :373         Min.   :0.0000   no :417   furnished     :140    \r\n yes:172         1st Qu.:0.0000   yes:128   semi-furnished:227    \r\n                 Median :0.0000             unfurnished   :178    \r\n                 Mean   :0.6936                                   \r\n                 3rd Qu.:1.0000                                   \r\n                 Max.   :3.0000                                   \r\n\r\nExplanation\r\nPrice:\r\nMinimum: The lowest selling price of a house in the dataset is $1,750,000.\r\n1st Quartile (Q1): 25% of the house prices are below $3,430,000.\r\nMedian: The median selling price (or the middle value) of houses in the dataset is $4,340,000.\r\nMean: The average selling price of houses in the dataset is approximately $4,766,729.\r\n3rd Quartile (Q3): 75% of the house prices are below $5,740,000.\r\nMaximum: The highest selling price of a house in the dataset is $13,300,000.\r\nArea:\r\nMinimum: The smallest house in the dataset has an area of 1,650 square feet.\r\n1st Quartile (Q1): 25% of the houses have an area below 3,600 square feet.\r\nMedian: The median area of houses in the dataset is 4,600 square feet.\r\nMean: The average area of houses in the dataset is approximately 5,151 square feet.\r\n3rd Quartile (Q3): 75% of the houses have an area below 6,360 square feet.\r\nMaximum: The largest house in the dataset has an area of 16,200 square feet.\r\nBedrooms:\r\nMinimum: The lowest number of bedroom in the dataset is 1.\r\n1st Quartile (Q1): 25% of the houses have below 2 and below bedroom.\r\nMedian: The median number of bedrooms in the dataset is 3 bedroom.\r\n3rd Quartile (Q3): 75% of the houses have 3 bedrooms and below.\r\nMaximum: The largest number of bedroom in the dataset is 6.\r\nBathrooms\r\nMinimum: The lowest number of bathrooms in the dataset is 1.\r\n1st Quartile (Q1): 25% of the houses have 1 bathroom.\r\nMedian: The median number of bathrooms in the dataset is 1.\r\n3rd Quartile (Q3): 75% of the houses have 2 and below bathrooms.\r\nMaximum: The highest number of bathroom in the dataset is 4.\r\nStories:\r\nMinimum: The lowest number of stories in the dataset is 1.\r\n1st Quartile (Q1): 25% of the houses have 1 story.\r\nMedian: The median number of stories in the dataset is 2.\r\n3rd Quartile (Q3): 75% of the houses have 2 and below storiess.\r\nMaximum: The highest number of stories in the dataset is 4.\r\nMainroad:\r\n77 houses are not located near a mainroad\r\n468 houses are located near a mainroad\r\nGuestroom\r\n354 houses do nt have a guestroom\r\n97 houses have guestroom\r\nBasement\r\n354 houses do not have a basement\r\n191 houses has a basement\r\nHotwaterheating\r\n520 houses do not have hot water heating\r\n25 houses have water heating\r\nAir conditioning\r\n373 houses do not have air conditioning\r\n172 houses have air conditioning\r\nPreferred area\r\n417 houses are not in a preferred area\r\n128 houses are in a preferred area\r\nFurnishing status:\r\n140 houses in the dataset are furnished\r\n227 houses are semi-furnished\r\n178 houses are unfurnished\r\nHistogram of price\r\n\r\n\r\nhouse %>% ggplot(aes(price, fill = \"red\"))+geom_histogram(color = \"blue\")+theme(\r\n  legend.position = \"none\"\r\n)\r\n\r\n\r\n\r\n\r\nThe dependent variable(Price) is not normally distributed\r\n\r\nTransformation of our dependent variable\r\n\r\n\r\nhouse$price <- log(house$price)\r\nhist(house$price,main = \"Histogram after log transformation\")\r\n\r\n\r\n\r\nFeature selection\r\n\r\n\r\nset.seed(111)\r\nfeature <- Boruta(price ~ ., data = house, doTrace = 2, maxRuns = 25)\r\nplot(feature, las = 2, cex.axis=0.7)\r\n\r\n\r\n\r\n\r\nno variable is deemed to be unimportant\r\nThe most top three important variables are: area,bathrooms and airconditioning.\r\n\r\nSplitting the Data\r\n\r\n\r\nset.seed(123)\r\ns <- initial_split(house, prop = 0.80)\r\ntrain <- training(s)\r\ntest <- testing(s)\r\n\r\n\r\nMultiple linear Regression\r\n\r\n\r\nm <- lm(price ~ .,data = train) %>% step(direction = \"backward\",trace = 0)\r\n\r\nsjPlot::tab_model(m, digits = 3, show.intercept = FALSE)\r\n\r\n\r\n \r\n\r\n\r\nprice\r\n\r\n\r\nPredictors\r\n\r\n\r\nEstimates\r\n\r\n\r\nCI\r\n\r\n\r\np\r\n\r\n\r\narea\r\n\r\n\r\n0.000\r\n\r\n\r\n0.000 – 0.000\r\n\r\n\r\n<0.001\r\n\r\n\r\nbedrooms\r\n\r\n\r\n0.021\r\n\r\n\r\n-0.008 – 0.050\r\n\r\n\r\n0.149\r\n\r\n\r\nbathrooms\r\n\r\n\r\n0.166\r\n\r\n\r\n0.125 – 0.207\r\n\r\n\r\n<0.001\r\n\r\n\r\nstories\r\n\r\n\r\n0.099\r\n\r\n\r\n0.073 – 0.125\r\n\r\n\r\n<0.001\r\n\r\n\r\nmainroad [yes]\r\n\r\n\r\n0.122\r\n\r\n\r\n0.066 – 0.179\r\n\r\n\r\n<0.001\r\n\r\n\r\nguestroom [yes]\r\n\r\n\r\n0.083\r\n\r\n\r\n0.032 – 0.134\r\n\r\n\r\n0.002\r\n\r\n\r\nbasement [yes]\r\n\r\n\r\n0.085\r\n\r\n\r\n0.041 – 0.128\r\n\r\n\r\n<0.001\r\n\r\n\r\nhotwaterheating [yes]\r\n\r\n\r\n0.208\r\n\r\n\r\n0.121 – 0.295\r\n\r\n\r\n<0.001\r\n\r\n\r\nairconditioning [yes]\r\n\r\n\r\n0.179\r\n\r\n\r\n0.135 – 0.223\r\n\r\n\r\n<0.001\r\n\r\n\r\nparking\r\n\r\n\r\n0.048\r\n\r\n\r\n0.025 – 0.072\r\n\r\n\r\n<0.001\r\n\r\n\r\nprefarea [yes]\r\n\r\n\r\n0.122\r\n\r\n\r\n0.076 – 0.169\r\n\r\n\r\n<0.001\r\n\r\n\r\nfurnishingstatus[semi-furnished]\r\n\r\n\r\n0.012\r\n\r\n\r\n-0.035 – 0.058\r\n\r\n\r\n0.626\r\n\r\n\r\nfurnishingstatus[unfurnished]\r\n\r\n\r\n-0.108\r\n\r\n\r\n-0.159 – -0.057\r\n\r\n\r\n<0.001\r\n\r\n\r\nObservations\r\n\r\n\r\n436\r\n\r\n\r\nR2 / R2 adjusted\r\n\r\n\r\n0.728 / 0.720\r\n\r\n\r\nInterpretation of Significant variables\r\nArea: A 1% increase in the area of the house corresponds to a 0.004637% increase in the price of the house.\r\nBathrooms: Each additional bathroom is associated with an approximate 16.62% increase in the house price.\r\nStories: Each additional story in the house corresponds to an approximate 9.88% increase in the house price.\r\nMainroad (Yes): Houses located on the main road tend to have prices higher by approximately 12.23% compared to those not on the main road.\r\nGuestroom (Yes): Houses with a guestroom have prices higher by approximately 8.30% compared to those without a guestroom.\r\nBasement (Yes): Similarly, houses with a basement tend to have prices higher by approximately 8.48% compared to those without.\r\nHotwaterheating (Yes): Houses with hot water heating have prices higher by approximately 20.82% compared to those without.\r\nAirconditioning (Yes): Similarly, houses with air conditioning tend to have prices higher by approximately 17.89% compared to those without.\r\nParking: Each additional parking space is associated with an approximate 4.844% increase in the house price.\r\nPrefarea (Yes): Houses in preferred areas have prices higher by approximately 12.24% compared to those not in preferred areas.\r\nFurnishing Status (Unfurnished): Unfurnished houses tend to have prices lower by approximately 10.79% compared to furnished ones.\r\nAdjusted R squared in my model is 72 percent meaning that my model explain 72 percent of variation in house prices. 28 percent is explained by other factors that are not in the model.\r\nChecking the model performance\r\n\r\n\r\nmodel_performance(m) %>% flextable::flextable()\r\n\r\nAICAICcBICR2R2_adjustedRMSESigma-168.5982-167.4553-107.43350.72820760.71983480.19268690.195857\r\n\r\nDiagnostic Tests\r\n1)Auto correlation\r\n\r\n\r\na <- check_autocorrelation(m)\r\na\r\n\r\nOK: Residuals appear to be independent and not autocorrelated (p = 0.528).\r\n\r\n2) Multcolinearity\r\n\r\n\r\nmc <- check_collinearity(m)\r\nplot(mc)\r\n\r\n\r\n\r\n3) Homoscedasticity\r\n\r\n\r\nh <- check_heteroscedasticity(m)\r\nplot(h)\r\n\r\n\r\n\r\n4) Normality test\r\n\r\n\r\nno <- check_normality(m)\r\nplot(no)\r\n\r\n\r\n\r\n5) Outliers\r\n\r\n\r\no <-check_outliers(m)\r\nplot(o)\r\n\r\n\r\n\r\n\r\n\r\n\r\nPredicting Using The Model\r\n\r\n\r\npred <- predict(m,newdata = test,type = \"response\")\r\nprediction <- exp(pred)\r\n\r\n\r\n\r\n\r\ntest$prediction <- prediction\r\ntest %>% mutate(Actual_price = exp(price)) %>% select(-1,predicted_price=prediction,Actual_price,everything()) %>% \r\n  select(Actual_price,predicted_price) %>% \r\n  datatable()\r\n\r\n\r\n\r\nLimitation of my model\r\nLimited Features:Even though there are no missing values, the dataset may still lack some important features that could affect house prices. Features like neighborhood amenities, crime rates, or access to public transportation could significantly impact house prices but are not be included in the dataset.\r\nData Bias:The dataset may be biased towards certain types of houses or neighborhoods, which could affect the model’s ability to generalize to other areas or housing markets. For example, if the dataset predominantly includes houses from affluent neighborhoods, the model’s predictions may not be accurate for houses in lower-income areas.\r\nThe dataset may not reflect current market conditions or trends. Changes in the housing market over time, such as shifts in demand, economic conditions, or regulatory changes, may not be captured in the dataset, potentially affecting the model’s predictive performance.\r\nGeographic Specificity:\r\nThe dataset may represent a specific geographic region or market, limiting the model’s generalizability to houses in other regions with different market dynamics and socioeconomic factors.\r\nExternal Factors:\r\nExternal factors like economic conditions, government policies, or natural disasters may influence house prices but may not be accounted for in the dataset. Ignoring these external factors could limit the accuracy and reliability of the model predictions.\r\nEvaluation Metrics:\r\nDatasource:\r\nKaggle\r\nlink : https://www.kaggle.com/datasets/yasserh/housing-prices-dataset\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:55:07+03:00"
    },
    {
      "path": "index.html",
      "title": "Economist/Data Analyst",
      "author": [],
      "contents": "\r\n\r\n          \r\n          \r\n          HOME\r\n          \r\n          \r\n          About Me\r\n          \r\n          \r\n          Blogs\r\n           \r\n          ▾\r\n          \r\n          \r\n          Statistical Tests\r\n          Regression Analysis\r\n          Data Visualization\r\n          Field Experiments\r\n          Why Dashboards in Business Environment\r\n          A Journey Through East Africa\r\n          Insights from The World Happiness Report 2023\r\n          Forecasting Kenya's Economic Future\r\n          \r\n          \r\n          \r\n          \r\n          Projects\r\n           \r\n          ▾\r\n          \r\n          \r\n          House prices Prediction\r\n          Disease Prediction Model(Breast Cancer)\r\n          Loan Eligibility Prediction\r\n          Customer Segmentation\r\n          Sales Dashboard\r\n          Analyzing Customer Churn for a Telecom Company\r\n          Sentiment Analysis of Product Reviews\r\n          Kenyan Budget Deficits and Growth\r\n          \r\n          \r\n          Contacts\r\n          My Resume\r\n          ☰\r\n          \r\n          \r\n      \r\n        \r\n          \r\n            Economist/Data Analyst\r\n          \r\n          \r\n            \r\n              Welcome to my Portfolio Website! Am Julius Ndung’u, a\r\n              Data Analyst with strong foundation in Economics and\r\n              Statistics complemented by certifications in Data\r\n              Analysis. Here you will find a showcase of my work,\r\n              including Statistical Tests,Interactive Dashboards,\r\n              Detailed case studies and projects across various domains\r\n              such as sales analysis, customer segmentation, sentiment\r\n              analysis and predictive modelling. my expertise lies in\r\n              transforming complex data sets into actionable insights\r\n              that drive strategic decision-making Explore my projects\r\n              and blogs to see my analytical skills in action. If you\r\n              have any question or wish to connect, please visit the\r\n              contact page.Thank you for visiting!\r\n            \r\n            \r\n              Welcome to my Portfolio Website! Am Julius Ndung’u, a\r\n              Data Analyst with strong foundation in Economics and\r\n              Statistics complemented by certifications in Data\r\n              Analysis. Here you will find a showcase of my work,\r\n              including Statistical Tests,Interactive Dashboards,\r\n              Detailed case studies and projects across various domains\r\n              such as sales analysis, customer segmentation, sentiment\r\n              analysis and predictive modelling. my expertise lies in\r\n              transforming complex data sets into actionable insights\r\n              that drive strategic decision-making Explore my projects\r\n              and blogs to see my analytical skills in action. If you\r\n              have any question or wish to connect, please visit the\r\n              contact page.Thank you for visiting!\r\n            \r\n          \r\n\r\n          \r\n            \r\n              \r\n                  \r\n                    \r\n                       Linkedin\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                      GitHub\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                       Email\r\n                    \r\n                  \r\n                \r\n                              \r\n          \r\n\r\n          \r\n            \r\n              \r\n                                \r\n                  \r\n                     Linkedin\r\n                  \r\n                \r\n                                \r\n                  \r\n                    GitHub\r\n                  \r\n                \r\n                                \r\n                  \r\n                     Email\r\n                  \r\n                \r\n                              \r\n            \r\n          \r\n        \r\n      \r\n    \r\n\r\n    \r\n    \r\n    \r\n          \r\n              Thank you for visiting my portfolio.🤝\r\n              \r\n               I look forward to connecting with you and exploring potential opportunities!\r\n              \r\n              © Copyright 2024 Julius. All rights reserved. \r\n              \r\n              Software licensed under the Apache License, v2.0. \r\n              \r\n              Built with Distill package in R.\r\n            \r\n          \r\n          \r\n\r\n    \r\n  ",
      "last_modified": "2024-06-21T21:55:17+03:00"
    },
    {
      "path": "Loan_eligibility_prediction.html",
      "title": "Smart Loan Approval System: Predictive Modeling for Better Decisions",
      "author": [
        {
          "name": "Julius Ndung'u",
          "url": {}
        }
      ],
      "date": "2024-04-17",
      "contents": "\r\nIntroduction\r\nDream Housing Finance company deals in all kinds of home loans. They\r\nhave presence across all urban, semi urban and rural areas. Customer\r\nfirst applies for home loan and after that company validates the\r\ncustomer eligibility for loan. Company wants to automate the loan\r\neligibility process (real time) based on customer detail provided while\r\nfilling online application form. These details are Gender, Marital\r\nStatus, Education, Number of Dependents, Income, Loan Amount, Credit\r\nHistory and others. To automate this process, they have provided a\r\ndataset to identify the customers segments that are eligible for loan\r\namount so that they can specifically target these customers.\r\nOverview of the Project\r\nThe primary objective of this project is to develop a robust loan\r\neligibility prediction system utilizing machine learning techniques. By\r\nleveraging historical data on loan applications and their outcomes, I\r\naim to construct models capable of classifying whether a loan\r\napplication should be accepted or rejected.\r\nObjective of the Project\r\nThe overarching goal of this project is twofold:\r\nTo facilitate more informed decision-making for financial\r\ninstitutions by providing them with a reliable tool for assessing\r\nloan eligibility.\r\nTo enhance the borrowing experience for clients by ensuring fair and\r\ntransparent evaluation of loan applications, thereby fostering trust\r\nand satisfaction.\r\nImportance of Loan Eligibility Prediction\r\nRisk Management: By accurately assessing the creditworthiness of\r\napplicants, financial institutions can mitigate the risk of default\r\nand minimize potential financial losses.\r\nEfficiency Enhancement: Automated loan eligibility prediction\r\nsystems streamline the application review process, reducing manual\r\nlabor and operational costs while improving efficiency.\r\nCustomer Satisfaction: Transparent and equitable evaluation of loan\r\napplications enhances customer satisfaction, fostering long-term\r\nrelationships and loyalty.\r\nCompliance Requirements: Adherence to regulatory guidelines and\r\ncompliance standards necessitates thorough assessment of loan\r\napplicants to ensure fair lending practices.\r\nVariables in the Dataset\r\nDescription of the Data\r\nVariable\r\nDescription\r\nLoan_ID\r\nUnique Loan ID\r\nGender\r\nMale/ Female\r\nMarried\r\nApplicant married (Y/N)\r\nDependents\r\nNumber of dependents\r\nEducation\r\nApplicant Education (Graduate/ Under Graduate)\r\nSelf_Employed\r\nSelf employed (Y/N)\r\nApplicantIncome\r\nApplicant income\r\nCoapplicantIncome\r\nCoapplicant income\r\nLoanAmount\r\nLoan amount in thousands\r\nLoan_Amount_Term\r\nTerm of loan in months\r\nCredit_History\r\ncredit history meets guidelines\r\nProperty_Area\r\nUrban/ Semi Urban/ Rural\r\nLoan_Status\r\n(Target) Loan approved (Y/N)\r\n\r\n\r\nPackages Used\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(caret)\r\nlibrary(rsample)\r\nlibrary(randomForest)\r\nlibrary(janitor)\r\nlibrary(rpart)\r\nlibrary(lime)\r\nlibrary(DT)\r\n\r\n\r\nData Importation\r\n\r\n\r\nloan <- read.csv(\"Loan_Data.csv\")%>% tibble()\r\n\r\n\r\nData Preprocessing\r\n\r\n\r\n# Replace empty strings with NA in specific columns\r\nloan <- loan %>%\r\n  mutate(Gender = na_if(Gender, \"\"),\r\n    Married = na_if(Married, \"\"),\r\n    Dependents = na_if(Dependents, \"\"),\r\n    Education = na_if(Education, \"\"),\r\n    Self_Employed = na_if(Self_Employed, \"\"),\r\n    Loan_ID = na_if(Loan_ID, \"\"),\r\n    Property_Area = na_if(Property_Area, \"\"),\r\n    Loan_Status = na_if(Loan_Status, \"\")\r\n  )\r\nloan <- loan %>% filter(complete.cases(.))\r\nlibrary(dplyr)\r\n\r\n# Convert specified columns to factors\r\nloan$Gender <- factor(loan$Gender)\r\nloan$Married <- factor(loan$Married)\r\nloan$Dependents <- factor(loan$Dependents)\r\nloan$Education <- factor(loan$Education)\r\nloan$Self_Employed <- factor(loan$Self_Employed)\r\nloan$Loan_Amount_Term <- factor(loan$Loan_Amount_Term)\r\nloan$Credit_History <- factor(loan$Credit_History)\r\nloan$Property_Area <- factor(loan$Property_Area)\r\nloan$Loan_Status <- factor(loan$Loan_Status)\r\n\r\n\r\nloan <- loan %>% select(-1)\r\n\r\n\r\nExplroratory Data Analysis\r\nGender Distribution in Loan Applications\r\n\r\n\r\n#EDA\r\ntheme_set(theme_classic())\r\nloan %>% group_by(Gender) %>% \r\n  summarise(count = n()) %>% \r\n  ggplot(aes(Gender,count, fill = Gender))+geom_col()+theme(\r\n    legend.position = \"none\"\r\n  )+labs(\r\n    y = \"Count\"\r\n  )+geom_label(aes(label = count))\r\n\r\n\r\n\r\n\r\nOut of the total applications analyzed, 86 were from Females, while\r\nover 394 were from males. This gender distribution underscores the\r\nimportance of further investigating potential factors influencing\r\nborrowing behavior among different demographic groups.\r\n\r\nMarital Status Distribution in Loan Applications\r\n\r\n\r\nloan %>% group_by(Married) %>% \r\n  summarise(count = n()) %>% \r\n  ggplot(aes(Married,count, fill = Married))+geom_col()+theme(\r\n    legend.position = \"none\"\r\n  )+labs(\r\n    y = \"Count\"\r\n  )+geom_label(aes(label = count))\r\n\r\n\r\n\r\nDistribution of Number of Dependents in Loan Applications\r\n\r\n\r\nloan %>% group_by(Dependents) %>% \r\n  summarise(count = n()) %>% \r\n  ggplot(aes(Dependents,count, fill = Dependents))+geom_col()+theme(\r\n    legend.position = \"none\"\r\n  )+labs(\r\n    y = \"Count\")+geom_label(aes(label = count))\r\n\r\n\r\n\r\n\r\nUnderstanding the distribution of dependents among applicants is\r\nessential for assessing their financial responsibilities and potential\r\nimpact on loan repayment capabilities.\r\n\r\nEducational Background Distribution in Loan Applications\r\n\r\n\r\nloan %>% group_by(Education) %>% \r\n  summarise(count = n()) %>% \r\n  ggplot(aes(Education,count, fill = Education))+geom_col()+theme(\r\n    legend.position = \"none\"\r\n  )+labs(\r\n    y = \"Count\")+geom_label(aes(label = count))\r\n\r\n\r\n\r\n\r\nUnderstanding the educational background of applicants is crucial as\r\nit may correlate with factors such as income level, employment\r\nopportunities, and financial literacy, all of which influence loan\r\neligibility and repayment capabilities.\r\n\r\nSelf-Employment Status Distribution in Loan Applications\r\n\r\n\r\nloan %>% group_by(Self_Employed) %>% \r\n  summarise(count = n()) %>% \r\n  ggplot(aes(Self_Employed,count, fill = Self_Employed))+geom_col()+theme(\r\n    legend.position = \"none\"\r\n  )+labs(\r\n    y = \"Count\")+geom_label(aes(label = count))\r\n\r\n\r\n\r\n\r\nThe proportion of self-employed applicants provides insights into the\r\ndiversity of employment types within the applicant pool and may\r\ninfluence risk assessment and loan approval decisions.\r\n\r\nDistribution of Loan Amount Terms in Loan Applications\r\n\r\n\r\nloan %>% group_by(Loan_Amount_Term) %>% \r\n  summarise(count = n()) %>% \r\n  ggplot(aes(Loan_Amount_Term,count, fill = Loan_Amount_Term))+geom_col()+theme(\r\n    legend.position = \"none\"\r\n  )+labs(\r\n    y = \"Count\", x = \"Duration of Payment\")+geom_label(aes(label = count))\r\n\r\n\r\n\r\n\r\nThe analysis reveals that the majority of loan applications, the\r\nhighest number, were for a loan term of 360 months (30 years). As the\r\nloan term decreases, the number of applications decreases accordingly.\r\nThis distribution indicates a preference among applicants for longer\r\nloan terms, potentially reflecting their financial planning and\r\nrepayment capabilities.\r\n\r\nDistribution of Credit History in Loan Applications\r\n\r\n\r\nc <- loan %>% select(Credit_History) \r\nc$Credit_History <- factor(c$Credit_History, levels =c(0,1), labels = c(\"No\",\"Yes\"))\r\n  \r\nc %>% group_by(Credit_History) %>% \r\n  summarise(count = n()) %>% \r\n  ggplot(aes(Credit_History,count, fill = Credit_History))+geom_col()+theme(\r\n    legend.position = \"none\"\r\n  )+labs(y = \"Count\", x = \"Credit History\")+geom_label(aes(label = count))\r\n\r\n\r\n\r\n\r\nUnderstanding the distribution of credit history among applicants is\r\ncrucial as it serves as a key factor in assessing their\r\ncreditworthiness and likelihood of loan repayment.\r\n\r\nDistribution of Property Area in Loan Applications\r\n\r\n\r\nloan %>% group_by(Property_Area) %>% \r\n  summarise(count = n()) %>% \r\n  ggplot(aes(Property_Area,count, fill = Property_Area))+geom_col()+theme(\r\n    legend.position = \"none\"\r\n  )+labs(\r\n    y = \"Count\", x = \"Property Area\")+geom_label(aes(label = count))\r\n\r\n\r\n\r\n\r\nUnderstanding the distribution of property areas provides insights\r\ninto the geographic preferences of loan applicants and may correlate\r\nwith factors such as lifestyle, employment opportunities, and property\r\nvalues.\r\n\r\nLoan Status Distribution in Loan Applications\r\n\r\n\r\nloan %>% group_by(Loan_Status) %>% \r\n  summarise(count = n()) %>% \r\n  ggplot(aes(Loan_Status,count, fill = Loan_Status))+geom_col()+theme(\r\n    legend.position = \"none\"\r\n  )+labs(\r\n    y = \"Count\")+geom_label(aes(label = count))\r\n\r\n\r\n\r\n\r\nAmong the analyzed loan applications, 332 were approved (labeled as\r\n“Y”), while 148 were rejected (labeled as “N”).\r\n\r\nData Partitioning: Splitting the Dataset for Training and Testing\r\nTraining Data\r\nThe training set comprises a portion of the original dataset, typically\r\nthe majority, and is used to train the machine learning model.This\r\nsubset contains labeled examples, where both the input features and the\r\ncorresponding target variable (in this case, loan status) are\r\nprovided.During the training phase, the model learns patterns and\r\nrelationships within the data, adjusting its parameters to minimize the\r\nprediction error.The model is exposed to the training data multiple\r\ntimes through iterations or epochs, optimizing its performance on the\r\ntask at hand.\r\nTesting Data\r\nThe testing set is a separate portion of the dataset reserved\r\nexclusively for evaluating the trained model’s performance. This subset\r\nalso contains labeled examples, but the model has not seen these\r\nexamples during the training phase. Once the model has been trained on\r\nthe training data, it is evaluated on the testing data to assess its\r\ngeneralization capability, i.e., how well it performs on unseen data.\r\nThe testing set provides an unbiased estimate of the model’s performance\r\nand helps identify potential issues such as overfitting (when the model\r\nlearns to memorize the training data rather than generalize from it).\r\n\r\n\r\nset.seed(1)\r\nloan <- upSample(loan, loan$Loan_Status)\r\nloan <- loan %>% select(-Class)\r\nsplit_loan <- initial_split(loan, prop = 0.8, strata = Loan_Status)\r\nloan_train <- training(split_loan)\r\nloan_test <- testing(split_loan)\r\n\r\n\r\n\r\n\r\ntabyl(loan_test$Loan_Status)\r\n\r\n loan_test$Loan_Status  n percent\r\n                     N 67     0.5\r\n                     Y 67     0.5\r\n\r\n\r\n\r\ntabyl(loan_train$Loan_Status)\r\n\r\n loan_train$Loan_Status   n percent\r\n                      N 265     0.5\r\n                      Y 265     0.5\r\n\r\nModel Selection: Choosing the Best Algorithm for Loan Eligibility Prediction\r\nRandom Forest Model\r\n\r\n\r\ncvcontrol <- trainControl(method=\"repeatedcv\", \r\n                          number = 5,\r\n                          repeats = 2,\r\n                          allowParallel=TRUE)\r\nset.seed(1) \r\n\r\nforest <- train(Loan_Status ~., data = loan_train,\r\n                method=\"rf\",\r\n                trControl=cvcontrol,\r\n                importance=TRUE)\r\n\r\n\r\nModel accuracy\r\n\r\n\r\n#prediction\r\np1  <- predict(forest, newdata = loan_test)\r\nconfusionMatrix(p1, reference = loan_test$Loan_Status, positive = \"Y\")\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction  N  Y\r\n         N 60  7\r\n         Y  7 60\r\n                                          \r\n               Accuracy : 0.8955          \r\n                 95% CI : (0.8309, 0.9417)\r\n    No Information Rate : 0.5             \r\n    P-Value [Acc > NIR] : <2e-16          \r\n                                          \r\n                  Kappa : 0.791           \r\n                                          \r\n Mcnemar's Test P-Value : 1               \r\n                                          \r\n            Sensitivity : 0.8955          \r\n            Specificity : 0.8955          \r\n         Pos Pred Value : 0.8955          \r\n         Neg Pred Value : 0.8955          \r\n             Prevalence : 0.5000          \r\n         Detection Rate : 0.4478          \r\n   Detection Prevalence : 0.5000          \r\n      Balanced Accuracy : 0.8955          \r\n                                          \r\n       'Positive' Class : Y               \r\n                                          \r\n\r\nDecision Tree Model\r\n\r\n\r\nlibrary(party)\r\nset.seed(1)\r\ntree_model <- train(Loan_Status ~ ., \r\n            data = loan_train,\r\n            method = \"ctree\", \r\n            trControl = cvcontrol)\r\ntrP2 <- predict(tree_model,newdata = loan_test,type = \"raw\")\r\nconfusionMatrix(trP2, reference = loan_test$Loan_Status, positive = \"Y\")\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction  N  Y\r\n         N 42 11\r\n         Y 25 56\r\n                                         \r\n               Accuracy : 0.7313         \r\n                 95% CI : (0.648, 0.8042)\r\n    No Information Rate : 0.5            \r\n    P-Value [Acc > NIR] : 4.055e-08      \r\n                                         \r\n                  Kappa : 0.4627         \r\n                                         \r\n Mcnemar's Test P-Value : 0.03026        \r\n                                         \r\n            Sensitivity : 0.8358         \r\n            Specificity : 0.6269         \r\n         Pos Pred Value : 0.6914         \r\n         Neg Pred Value : 0.7925         \r\n             Prevalence : 0.5000         \r\n         Detection Rate : 0.4179         \r\n   Detection Prevalence : 0.6045         \r\n      Balanced Accuracy : 0.7313         \r\n                                         \r\n       'Positive' Class : Y              \r\n                                         \r\n\r\nLogistic regression\r\n\r\n\r\nlogit <- glm(Loan_Status ~., data = loan_train, family = \"binomial\")\r\nl_p <- predict(logit, newdata = loan_test, type = \"response\")\r\nl_p<- ifelse(l_p > 0.5, \"Y\",\"N\")\r\nl_p <- factor(l_p)\r\nconfusionMatrix(l_p, reference = loan_test$Loan_Status, positive = \"Y\")\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction  N  Y\r\n         N 42 18\r\n         Y 25 49\r\n                                         \r\n               Accuracy : 0.6791         \r\n                 95% CI : (0.593, 0.7571)\r\n    No Information Rate : 0.5            \r\n    P-Value [Acc > NIR] : 2.056e-05      \r\n                                         \r\n                  Kappa : 0.3582         \r\n                                         \r\n Mcnemar's Test P-Value : 0.3602         \r\n                                         \r\n            Sensitivity : 0.7313         \r\n            Specificity : 0.6269         \r\n         Pos Pred Value : 0.6622         \r\n         Neg Pred Value : 0.7000         \r\n             Prevalence : 0.5000         \r\n         Detection Rate : 0.3657         \r\n   Detection Prevalence : 0.5522         \r\n      Balanced Accuracy : 0.6791         \r\n                                         \r\n       'Positive' Class : Y              \r\n                                         \r\n\r\nBest model\r\nBased on the comparison of the metrics, the Random Forest model\r\noutperforms both the Decision Tree and Logistic Regression models in\r\nterms of accuracy, sensitivity, specificity, and positive predictive\r\nvalue. It achieves the highest accuracy (89.55%), sensitivity (89.55%),\r\nand positive predictive value (89.55%) among the three models,\r\nindicating its effectiveness in correctly classifying loan applications.\r\nDecision tree model accuracy is 73.13% which is lower than the\r\nrandomforest model.\r\nOn the other hand, the Logistic Regression model shows an accuracy of\r\n67.91% but it falls short of the Random Forest model in terms of overall\r\naccuracy and positive predictive value.\r\nOverall, based on the provided metrics, the Random Forest model emerges\r\nas the best-performing model for predicting loan eligibility, offering a\r\ngood balance between accuracy, sensitivity, and specificity, and\r\ndemonstrating robust performance across multiple evaluation criteria.\r\nPredicting Cases Using the Randomforest Model\r\n\r\n\r\nloan_test$prediction <- p1\r\nloan_test %>%\r\nselect(Loan_Status,prediction) %>% datatable()\r\n\r\n\r\n\r\nAssociation for Artificial Intelligence 2023 et al. (2023)\r\n\r\n\r\n\r\nAssociation for Artificial Intelligence 2023, Ling Chen, Lei Chen, Pan Gang, Yongrui Huang, Shijian Li, Chunping Wang, and Sha Zhao. 2023. “Loan Fraud Users Detection in Online Lending Leveraging Multiple Data Views.” https://doi.org/10.48448/3EPT-MG13.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:56:47+03:00"
    },
    {
      "path": "product_review.html",
      "title": "Sentiment Analysis of Product Reviews",
      "author": [
        {
          "name": "Julius Ndung'u",
          "url": {}
        }
      ],
      "date": "2024-04-30",
      "contents": "\r\nIntroduction\r\nIn the hospitality industry, understanding customer opinions and sentiments is crucial for maintaining high levels of customer satisfaction and improving overall service quality. Sentiment analysis of hotel reviews provides valuable insights into customer preferences, opinions, and experiences, enabling hotel management to identify areas for improvement and make informed decisions.\r\nIn this project, I conduct sentiment analysis on a dataset of hotel reviews to understand the overall sentiment expressed by customers. I analyze the frequency of positive, negative, and neutral sentiments, as well as the distribution of specific emotions such as joy, trust, anger, and sadness. Additionally, I explore the most frequently mentioned words in the reviews to identify common themes and aspects of the hotel experience that are frequently mentioned by customers.\r\nBy analyzing hotel reviews using sentiment analysis techniques, I aim to provide actionable insights that can help hotel management enhance the customer experience, address areas of concern, and ultimately improve customer satisfaction and loyalty.\r\npackages\r\n\r\n\r\nlibrary(tm)\r\nlibrary(SnowballC)\r\nlibrary(wordcloud)\r\nlibrary(syuzhet)\r\n\r\n\r\nData Importation and Preparation\r\n\r\n\r\ndata_nlp <- read.csv(\"Restaurant_Reviews.tsv\",\r\n                     sep = '\\t',quote = '',stringsAsFactors = F)\r\n\r\n#specifying the vector with text messages\r\ncorpus <- VCorpus(VectorSource(data_nlp$Review))\r\n#transforming the content to lower case\r\ncorpus <- tm_map(corpus,content_transformer(tolower))\r\n#removing numbers\r\ncorpus <- tm_map(corpus,removeNumbers)\r\n#removing punctuation\r\ncorpus <- tm_map(corpus,removePunctuation)\r\n#removing stopwords\r\ncorpus <- tm_map(corpus,removeWords,stopwords())\r\n#getting root of the word\r\ncorpus <- tm_map(corpus, stripWhitespace)\r\ncorpus <- tm_map(corpus, stemDocument)\r\ndata <- DocumentTermMatrix(corpus)\r\n#removing column with less words\r\ndata <- removeSparseTerms(data, 0.999)\r\ndataset <- data.frame(as.matrix(data))\r\ndataset$liked <- data_nlp$Liked\r\n\r\n\r\nData Analysis\r\nMost Repeated Words\r\n\r\n\r\nfrequency <- colSums(as.matrix(data))\r\norder <- order(frequency,decreasing = T)\r\nfirst_ten <- frequency[head(order,10)]\r\nnm = names(first_ten)\r\ndata2 <-data.frame(name = names(first_ten) ,occur = first_ten)\r\nfirst_ten\r\n\r\n  food  place   good servic  great   back   time   like   will realli \r\n   125    112     95     84     70     61     55     51     37     36 \r\n\r\nFood (125 mentions)\r\nThe word “food” is the most frequently mentioned word in the reviews, with 125 mentions.This indicates that customers place a significant emphasis on the quality of food provided by the hotel.The frequency of this word suggests that food plays a crucial role in the overall experience of the customers.\r\nPlace (112 mentions)\r\n“Place” is the second most repeated word in the reviews, with 112 mentions.Customers often mention the hotel’s location or overall ambiance using this word.The frequency of this word indicates that customers consider the hotel’s location as an important factor in their experience.\r\nGood (95 mentions)\r\n“Good” is frequently used by customers to describe various aspects of their experience, such as service, food, ambiance, etc.Its high frequency suggests that customers generally have positive opinions about different aspects of the hotel.\r\nService (84 mentions)\r\nCustomers frequently mention “service” in their reviews, with 84 mentions.\r\nThis indicates that the quality of service provided by the hotel staff is an important aspect of the customer experience.\r\nCustomers often express their satisfaction or dissatisfaction with the service using this word.\r\nGreat (70 mentions)\r\n“Great” is often used by customers to express positive opinions about various aspects of the hotel, such as service, food, ambiance, etc.Its high frequency suggests that customers have a generally positive impression of the hotel.\r\nBack (61 mentions)\r\n“Back” is frequently used by customers to express their intention to return to the hotel.Its frequency suggests that customers are satisfied with their experience and are likely to revisit the hotel in the future.\r\nTime (55 mentions)\r\nCustomers often mention “time” in the context of their experience at the hotel, such as the time spent dining, relaxing, etc.Its frequency suggests that customers value their time spent at the hotel and consider it an important aspect of their experience.\r\nLike (51 mentions)\r\n“Like” is frequently used by customers to express positive opinions about various aspects of the hotel, such as food, service, ambiance, etc.Its frequency suggests that customers have a generally positive impression of different aspects of the hotel.\r\nWill (37 mentions)\r\n“Will” is often used by customers to express their intention to revisit or recommend the hotel to others.Its frequency suggests that customers are satisfied with their experience and are likely to recommend the hotel to others.\r\nReally (36 mentions)\r\n“Really” is often used by customers to emphasize their opinions or experiences.\r\nIts frequency suggests that customers often use this word to express strong positive opinions about various aspects of the hotel.\r\nGraphical Representation of Most Repeated Word\r\n\r\n\r\nwordcloud(names(first_ten),first_ten,min.freq = 30,colors = brewer.pal(6,\"Dark2\"))\r\n\r\n\r\n\r\nSentiment Analysis\r\n\r\n\r\nreview <- iconv(data_nlp$Review)\r\n# getting the sentiments\r\ns <- get_nrc_sentiment(review)\r\ns$neutral <- ifelse(s$positive+s$negative == 0,1,0)\r\n\r\nbarplot(100*colSums(s)/sum(s),\r\n        las = 3,\r\n        col = rainbow(10),\r\n        ylab = \"Percentage\",\r\n        main = \"Sentiment score for hotel reviews\")\r\n\r\n\r\n\r\nThe sentiment analysis indicates that the majority of customers have a positive experience at the hotel, with trust and joy being the most prevalent positive emotions expressed in the reviews. However, it’s important for the hotel management to address any negative sentiments expressed by customers and work towards improving customer satisfaction.\r\nThis analysis provides valuable insights into customer opinions and sentiments, which can be used by the hotel management to make informed decisions and improve the overall customer experience.\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:58:01+03:00"
    },
    {
      "path": "regression.html",
      "title": "Regression",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:58:05+03:00"
    },
    {
      "path": "Resume.html",
      "title": "Resume",
      "author": [],
      "contents": "\r\nMY RESUME\r\nClick here to View My Resume\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:58:08+03:00"
    },
    {
      "path": "Sales_Dashboard.html",
      "title": "Sales Dashboard",
      "description": "The Sales Dashboard project aims to provide a dynamic and interactive overview of a Retail's sales performance. \n",
      "author": [
        {
          "name": "Julius Ndung'u",
          "url": {}
        }
      ],
      "date": "2024-04-24",
      "contents": "\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:58:12+03:00"
    },
    {
      "path": "Statistical_Test.html",
      "title": "Statistical Test",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2024-06-21T21:58:17+03:00"
    }
  ],
  "collections": ["viz/viz.json", "regression/regression.json", "math/math.json"]
}
